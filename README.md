# STEP

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<p style="text-align:center">
<a href="https://doi.org/10.5281/zenodo.7480413"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.7480413.svg" alt="DOI"></a>
</p>
<p style="text-align:center">
<a href="#getting-started">Get started</a> \|
<a href="https://borjarequena.github.io/step/">Documentation</a> \|
<a href="https://borjarequena.github.io/step/tutorials/index_tutorials.html">Tutorials</a>
\| <a href="#cite-us\">Cite us</a>
</p>

STEP is a machine learning pipeline to study time-dependent diffusion
properties by extracting them at every time step of the input
trajectories. This allows us to see where changes in the diffusive
behaviour occur (if there are any). The method was originally developed
for the paper “[Inferring pointwise diffusion properties of single
trajectories with deep learning](https://arxiv.org/abs/2302.00410)”.

Studying diffusive trajectories, we can extract meaningful parameters to
understand their underlying physical and biological processes. However,
quantifying the trajectories is a challenging task due to their
stochastic nature and other associated technical drawbacks, such as the
presence of noise in the acquisition. Furthermore, we often encounter
changes in the motion properties through time, which adds on to the
complexity. Typically, these changes are associated with interactions
between the tracked particles (from animals in the wild to proteins in a
cell) with other components in their environments.

Therefore, accurately characterizing these time-dependent properties of
motion can provide us with deep insight about the physical systems that
we are studying. With our work, we contribute to the community effort of
studying diffusive processes with state-of-the-art machine learning
techniques, instigated by initiatives like the [AnDi
Challenge](https://www.nature.com/articles/s41467-021-26320-w). We
propose STEP: a method to extract the diffusion properties of
trajectories at every time step. This way, we can easily see any
possible changes through time both sudden and continuous, without any
prior assumption about the system.

We provide a [python library](https://github.com/BorjaRequena/step) with
[extensive documentation](https://borjarequena.github.io/step/) to
simulate time-dependent diffusive processes, train machine learning
models to characterize them, and analyze their performance. Follow our
[tutorials](https://borjarequena.github.io/step/tutorials/index_tutorials.html)
to get familiar with our method, reproduce our results, and use STEP to
analyze your experiments!

<div>

> **Note**
>
> We use the [AnDi datasets
> library](https://andichallenge.github.io/andi_datasets/) to simulate
> the anomalous diffusion segments in the trajectories.

</div>

# Getting started

In order to use our library, you will need a system with `python>=3.10`.
Then, you can install STEP by first cloning our repository in your
filesystem:

    git clone https://github.com/BorjaRequena/step.git
    cd step
    pip install .

This will install all the necessary dependencies to make full use of the
library.

To train the machine learning models, we recommend using a GPU to take
full advantage of [PyTorch](https://pytorch.org/). A viable option is to
use [Google colab](https://colab.research.google.com/). There, you can
use hardware accelerators (GPUs and TPUs) from the menu
`Runtime>Change runtime type` and selecting your desired accelerator in
the `Hardware accelerator` dropdown menu.

# Contributing

Contributions are more than welcome! Should you need support for a new
feature, [open an
issue](https://github.com/BorjaRequena/step/issues/new/choose)! If you
feel like developing it yourself, [open a pull
request](https://github.com/BorjaRequena/step/compare)!

This repository is based on [nbdev](https://nbdev.fast.ai/). Therefore,
you should get familiar with the [basics of
nbdev](https://nbdev.fast.ai/getting_started.html) beforehand. However,
if you have any doubt, you can open a pull request and ask us. We’ll be
more than happy to help you out!

To be able to contribute, you’ll have to first [fork the
repository](https://github.com/BorjaRequena/step/fork). Then, clone the
fork to your local system and install it in editable mode:

    git clone https://github.com/YourUserName/step.git
    cd step
    pip install -e .

Then, you’ll have to create a branch in your fork where you will commit
your edits.

    git checkout -b my-feature

Once you have commited the first changes to the branch, you can already
[open a pull request](https://github.com/BorjaRequena/step/compare) to
merge it into our master branch. This way, we can see your progress and
help you with the integration from the start.

# Cite us

If you use this library, please cite us! We would appreciate both a
citation to the library and to our original work.

To cite the original work:

    @misc{Requena2023STEP,
      author    = {Requena, Borja and Mas\'o, Sergi and Bertran, Joan and
                   Lewenstein, Maciej and Manzo, Carlo and Mu{\~n}oz-Gil, Gorka},
      title     = {Inferring pointwise diffusion properties of single
                   trajectories with deep learning},
      doi       = {10.48550/ARXIV.2302.00410},
      url       = {https://arxiv.org/abs/2302.00410},
      publisher = {arXiv},
      year      = {2023},
      keywords  = {Soft Condensed Matter (cond-mat.soft),
                   Biological Physics (physics.bio-ph),
                   Data Analysis, Statistics and Probability (physics.data-an),
                   Quantitative Methods (q-bio.QM), FOS: Physical sciences,
                   FOS: Biological sciences, FOS: Biological sciences},
      copyright = {Creative Commons Attribution Share Alike 4.0 International}
    }

To cite the library:

    @software{Requena2022step,
      author    = {Requena, Borja and Mu{\~n}oz-Gil, Gorka},
      title     = {BorjaRequena/step},
      month     = dec,
      year      = 2022,
      publisher = {Zenodo},
      doi       = {10.5281/zenodo.7480413},
      url       = {https://doi.org/10.5281/zenodo.7480413}
    }
