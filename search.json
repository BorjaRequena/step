[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Getting started",
    "section": "",
    "text": "— STEP —\nGet started | Documentation | Tutorials | Cite us"
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "Getting started",
    "section": "Contributing",
    "text": "Contributing\n\nContributions are more than welcome! Should you need support for a new feature, open an issue! If you feel like developing it yourself, open a pull request!\nThis repository is based on nbdev. Therefore, you should get familiar with the basics of nbdev beforehand. However, if you have any doubt, you can open a pull request and ask us. We’ll be more than happy to help you out!\nTo be able to contribute, you’ll have to first fork the repository. Then, clone the fork to your local system and install it in editable mode:\ngit clone https://github.com/YourUserName/step.git\ncd step\npip install -e .\nThen, you’ll have to create a branch in your fork where you will commit your edits.\ngit checkout -b my-feature\nOnce you have commited the first changes to the branch, you can already open a pull request to merge it into our master branch. This way, we can see your progress and help you with the integration from the start."
  },
  {
    "objectID": "index.html#cite-us",
    "href": "index.html#cite-us",
    "title": "Getting started",
    "section": "Cite us",
    "text": "Cite us\nIf you use this library, please cite us! We would appreciate both a citation to the library and to our original work.\nTo cite the original work:\n@misc{Requena2023STEP,\n  author    = {Requena, Borja and Mas\\'o, Sergi and Bertran, Joan and\n               Lewenstein, Maciej and Manzo, Carlo and Mu{\\~n}oz-Gil, Gorka},\n  title     = {Inferring pointwise diffusion properties of single\n               trajectories with deep learning},\n  doi       = {10.48550/ARXIV.2302.00410},\n  url       = {https://arxiv.org/abs/2302.00410},\n  publisher = {arXiv},\n  year      = {2023},\n  keywords  = {Soft Condensed Matter (cond-mat.soft),\n               Biological Physics (physics.bio-ph),\n               Data Analysis, Statistics and Probability (physics.data-an),\n               Quantitative Methods (q-bio.QM), FOS: Physical sciences,\n               FOS: Biological sciences, FOS: Biological sciences},\n  copyright = {Creative Commons Attribution Share Alike 4.0 International}\n}\nTo cite the library:\n@software{Requena2022step,\n  author    = {Requena, Borja and Mu{\\~n}oz-Gil, Gorka},\n  title     = {BorjaRequena/step},\n  month     = dec,\n  year      = 2022,\n  publisher = {Zenodo},\n  doi       = {10.5281/zenodo.7480413},\n  url       = {https://doi.org/10.5281/zenodo.7480413}\n}"
  },
  {
    "objectID": "source/models.html",
    "href": "source/models.html",
    "title": "Models",
    "section": "",
    "text": "source\n\n\n\n tfm_encoder (dim, n_head=1, n_layers=8, dim_ff=1024, dropout=0.1,\n              activation='relu')\n\nCreates a nn.TransformerEncoder.\n\nsource\n\n\n\n\n ConcatPooling (dim=-1)\n\nPerform max and average pool over dim. Outputs [avg_pool, max_pool].\n\nsource\n\n\n\n\n Transpose (dims)\n\nTransposition layer of dims.\n\nsource\n\n\n\n\n Normalization (dim=-1)\n\nZ-Normalization over the designated dimension.\n\nsource\n\n\n\n\n get_act (vocab_sz, yrange=(0, 2.05))\n\nProvides a sigmoid or softmax activation according to inferring the task (regression or classification) from vocab_sz."
  },
  {
    "objectID": "source/models.html#u-net",
    "href": "source/models.html#u-net",
    "title": "Models",
    "section": "U-net",
    "text": "U-net\nU-nets were originally conceived to perform image segmentation. Therefore, they are particularly well-suited for the trajectory segmentation task.\nWe provide a dynamic U-net that takes the backbone of a model and transforms it into the U-like architecture.\n\nsource\n\nicnr_init_general\n\n icnr_init_general (x, scale=2, init=&lt;function kaiming_normal_&gt;)\n\nGeneralized version of icnr_init.\n\nsource\n\n\nGeneralPixleShuffle\n\n GeneralPixleShuffle (upscale_factor)\n\nGeneralized Pixle Shuffle to work with any data dimensionality.\n\nsource\n\n\nPixelShuffleUpsampling\n\n PixelShuffleUpsampling (ni, nf=None, scale=2, ndim=2, blur=False,\n                         norm_type=&lt;NormType.Weight: 3&gt;, act_cls=&lt;class\n                         'torch.nn.modules.activation.ReLU'&gt;)\n\nUpdample by scale from ni filters to nf using GeneralPixleShuffle.\n\nsource\n\n\nUnetBlock\n\n UnetBlock (up_in_c, x_in_c, hook, ndim=1, final_div=True, blur=False,\n            act_cls=&lt;class 'torch.nn.modules.activation.ReLU'&gt;,\n            self_attention=False, init=&lt;function kaiming_normal_&gt;,\n            norm_type=None, ks=3, stride=1, padding=None, bias=None,\n            bn_1st=True, transpose=False, xtra=None, bias_std=0.01,\n            dilation:Union[int,Tuple[int,int]]=1, groups:int=1,\n            padding_mode:str='zeros', device=None, dtype=None)\n\nA quasi-UNet block using pixel shuffle upsampling.\nA key element of the U-net is the upsmapling branch. We do it by stacking UnetBlocks that perform convolution-based upsampling with pixel shuffle. We implement a PixelShuffleUpsampling layer that uses our GeneralPixleShuffle, which is a generalized version of the original pixel shuffle.\nTo build the downsampling branch, we take the desired architecture and we pass a dummy input through it to extract relevant information, such as the points at which dimensions change, which then need to be connected to the upsampling branch.\n\nsource\n\n\ndummy_eval\n\n dummy_eval (m, size=(64, 64))\n\nEvaluate m on a dummy input of a certain size\n\nsource\n\n\nin_channels\n\n in_channels (m)\n\nReturn the shape of the first weight layer in m.\n\nsource\n\n\nmodel_sizes\n\n model_sizes (m, size=(64, 64))\n\nPass a dummy input through the model m to get the various sizes of activations.\n\nsource\n\n\nget_sz_change_idxs\n\n get_sz_change_idxs (sizes)\n\nGet the indexes of the layers where the size of the activation changes.\n\nsource\n\n\nResizeToOrig\n\n ResizeToOrig (mode='nearest')\n\nMerge a shortcut with the module result by adding or concatenating them if dense=True.\n\nsource\n\n\nAttnDynamicUnet\n\n AttnDynamicUnet (encoder, n_out, img_size, ndim=1, num_encoder_layers=6,\n                  nhead_enc=8, dim_ff=1024, p=0.1, act='relu', blur=False,\n                  blur_final=True, self_attention=False, y_range=None,\n                  last_cross=True, bottle=False, act_cls=&lt;class\n                  'torch.nn.modules.activation.ReLU'&gt;, init=&lt;function\n                  kaiming_normal_&gt;, norm_type=None, **kwargs)\n\nCreate a U-Net from a given architecture.\nAttnDynamicUnet builds a U-net like architecture from a given architecture (encoder). The input encoder conforms the downsampling branch, then, we add a convolution and a transformer encoder at the center (bottom of the U), and build the upsampling branch with UnetBlocks that have skip connections wherever the dimension in the encoder changes.\n\nsource\n\n\nUnetModel\n\n UnetModel (encoder, n_class, img_size, nf=64, linear_layers=[128], p=0.1,\n            y_range=(0, 2.05), ndim=1, num_encoder_layers=6, nhead_enc=8,\n            dim_ff=1024, act='relu', blur=False, blur_final=True,\n            self_attention=False, last_cross=True, bottle=False,\n            act_cls=&lt;class 'torch.nn.modules.activation.ReLU'&gt;,\n            init=&lt;function kaiming_normal_&gt;, norm_type=None)\n\nU-net with a final dense layer.\nUnetModel uses AttnDynamicUnet to build a U-net from a desired architecture and appends a Classifier at the end to obtain the desired output dimension for the task.\nFor example, we can easily build a U-net with an XResNet encoder to infer the anomalous diffusion exponent \\(\\alpha\\) at every time step of the input trajectories.\n\ndls = get_segmentation_dls(target='y_exp')\ndls.device = default_device()\nencoder = XResBlocks(ResBlock, [1, 2, 1], c_in=1, stem_szs=(32,), block_szs=[64, 128, 256])\numodel = UnetModel(encoder, 1, (200,), num_encoder_layers=4, dim_ff=512, linear_layers=[], y_range=(0, 2.05))\numodel.to(default_device())\nulearn = Learner(dls, umodel, loss_func=L1LossFlat(), model_dir=MODEL_PATH)\n\n\nulearn.fit_one_cycle(15, lr_max=1e-3)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.353012\n0.344957\n00:35\n\n\n1\n0.335089\n0.334739\n00:35\n\n\n2\n0.332037\n0.327504\n00:35\n\n\n3\n0.324102\n0.323693\n00:36\n\n\n4\n0.317840\n0.316003\n00:36\n\n\n5\n0.312131\n0.314038\n00:36\n\n\n6\n0.309137\n0.310193\n00:35\n\n\n7\n0.308097\n0.305047\n00:35\n\n\n8\n0.303723\n0.304123\n00:36\n\n\n9\n0.299942\n0.302303\n00:36\n\n\n10\n0.299658\n0.300621\n00:36\n\n\n11\n0.297696\n0.300281\n00:36\n\n\n12\n0.293374\n0.299450\n00:36\n\n\n13\n0.292193\n0.299131\n00:36\n\n\n14\n0.290734\n0.299084\n00:36"
  },
  {
    "objectID": "source/utils.html",
    "href": "source/utils.html",
    "title": "Utils",
    "section": "",
    "text": "Tensor operations\n\nsource\n\nget_displacements\n\n get_displacements (x)\n\nReturns the displacements of trajectory x [dim, length].\n\nsource\n\n\nsplit_tensor\n\n split_tensor (t, indices)\n\nSplits input tensor t according to indices in the first dimension.\n\nsource\n\n\nlengths_from_cps\n\n lengths_from_cps (cps, length=200)\n\nReturns segment lengths determined by cps and a total length length.\n\n\n\nSegmentation post-processing\n\nsource\n\nfit_segments\n\n fit_segments (pred, pen=1.0, return_cps=False, kernel='linear',\n               min_size=2, jump=1, params=None)\n\nFit piecewise constant segments to input signal pred.\nfit_segments is mainly intended to process predictions of continuous values. However, the following functinos are mainly intended to post-process discrete predictions. Notably, post_process_prediction takes a prediction of discrete categories over a trajectory and extracts the most likely changepoints and segments, minimizing the impact of spurious mistakes along the predicted segment (see the example below).\n\nsource\n\n\npost_process_prediction\n\n post_process_prediction (pred, n_change_points=1)\n\nSegmentation prediction post-processing to find change points and classes.\n\nsource\n\n\nabundance\n\n abundance (val, t)\n\nAbundance of value val in tensor t.\n\nsource\n\n\nmajority_vote\n\n majority_vote (t)\n\nReturns majoritary value from t.\n\nsource\n\n\nget_split_classes\n\n get_split_classes (splits)\n\nReturns majority class of each split.\n\nsource\n\n\nchange_points_from_splits\n\n change_points_from_splits (splits)\n\nReturns change point position from split tensor.\n\nsource\n\n\nget_splits\n\n get_splits (t)\n\nSplits tensor t into chunks with the same value.\n\nsource\n\n\nfind_change_points\n\n find_change_points (t)\n\nFinds points in tensor t where the value changes.\n\nprediction = tensor([0, 0, 0, 0, 1, 1, 0, 0, 2, 2, 2, 2, 1, 2, 2])\ncps, classes, splits = post_process_prediction(prediction)\ncps, classes, splits\n\n(tensor([8]),\n [tensor([0]), tensor([2])],\n [tensor([0, 0, 0, 0, 1, 1, 0, 0]), tensor([2, 2, 2, 2, 1, 2, 2])])\n\n\n\n\n\nModel evaluation\n\nsource\n\nmean_relative_error\n\n mean_relative_error (pred, true, base=10)\n\nMean relative error assuming pred and true in log_base.\n\nsource\n\n\nmean_absolute_error\n\n mean_absolute_error (pred, true)\n\nMean absolute error between pred and true.\n\nsource\n\n\njaccard_index\n\n jaccard_index (true_positive, false_positive, false_negative)\n\nComputes the Jaccard index a.k.a. Tanimoto index.\n\nsource\n\n\nassign_changepoints\n\n assign_changepoints (true, pred)\n\nMatches predicted and true changepoints solving a linear sum assignment problem.\n\nsource\n\n\nevaluate_cp_prediction\n\n evaluate_cp_prediction (true, pred, changepoint_threshold=5)\n\nEvaluates the change point prediction.\nSince the changepoint detection algorithm can provide an arbitrary number of change points, we solve a linear sum assignment problem to perform the matching between the ground truth and the predicted changepoints.\nThen, we consider a valid prediction, i.e., a true positive (TP), those changepoints that lie within a trheshold of their corresponding ground truth. This way, all the predicted change points that are not TP are false positives (FP). Finally, the ground truth change points that do not have a predicted counterpart within the threshold are false negatives (FN).\nTo evaluate the change point detection, we use the Jaccard index, which is a function of the TP, FP and FN: \\[JI = \\frac{TP}{TP + FP + FN}\\,.\\]\n\nsource\n\n\nvalidate_andi_3_alpha\n\n validate_andi_3_alpha (m, dim=1, task=3, bs=128, pct=1, path=None)\n\nValidates model on the AnDi test set for task 3 (segmentation) predicting anomalous exponents.\n\nsource\n\n\nvalidate_andi_3_models\n\n validate_andi_3_models (m, dim=1, task=3, bs=128, pct=1, path=None)\n\nValidates model on the AnDi test set for task 3 (segmentation) predicting diffusion models.\n\nsource\n\n\nvalidate_andi_1\n\n validate_andi_1 (m, dim=1, bs=1, pct=1, task=1, path=None)\n\nValidates model on the AnDi test set for task 1 (anomalous exponent).\n\nsource\n\n\neval_andi_metrics\n\n eval_andi_metrics (dls, model)\n\nEvaluates model in validation set in order to obtain AnDi challenge metrics.\n\n\n\nFigures\nHere, we define colors and colormaps for our plots.\n\ncolor_order = ['blue', 'orange', 'yellow', 'purple', 'green']\ncolor_dict = {\n    'blue':   {'dark': (0.2745098, 0.4, 0.6),\n               'medium': (0.39607843, 0.5254902, 0.71764706),\n               'light': (0.65098039, 0.79215686, 0.94117647)},\n    'orange': {'dark': (0.71764706, 0.36470588, 0.24313725),\n               'medium': (0.88627451, 0.4627451, 0.34901961),\n               'light': (1.0, 0.63921569, 0.44705882)},\n    'yellow': {'dark': (0.85882353, 0.58431373, 0.18039216),\n               'medium': (0.89803922, 0.68235294, 0.39607843),\n               'light': (0.96470588, 0.84705882, 0.52941176)},\n    'purple': {'dark': (0.6627451, 0.16078431, 0.30980392),\n               'medium': (0.7372549, 0.39607843, 0.55294118),\n               'light': (0.89019608, 0.38823529, 0.52941176)},\n    'green':  {'dark': (0.22352941, 0.46666667, 0.4549019607843137),\n               'medium': (0.29803922, 0.60784314, 0.58431373),\n               'light': (0.50980392, 0.76862745, 0.76470588)}\n}\n\ncolors = [color_dict[k]['medium'] for k in color_order]\ncolors_light = [color_dict[k]['light'] for k in color_order]\ncolors_dark = [color_dict[k]['dark'] for k in color_order]\n\ncmap_hist1 = clr.LinearSegmentedColormap.from_list(\n    'custom cm', ['w', \n                  color_dict['blue']['light'],\n                  color_dict['blue']['dark']],\n                  N=256\n)\ncmap_hist2 = clr.LinearSegmentedColormap.from_list(\n    'custom cm', ['w', \n                  color_dict['orange']['light'],\n                  color_dict['orange']['dark']],\n                  N=256\n)\ncmap_points = clr.LinearSegmentedColormap.from_list(\n    'custom cm', [color_dict['yellow']['light'], \n                  color_dict['purple']['light'],\n                  color_dict['blue']['medium']],\n                  N=256\n)\n\nfig_size = 4\nlinewidth = 2\nalpha_grid = 0.2\nscatter_size = 12\n\nD_units = \"($\\mu$m$^2$/s)\""
  },
  {
    "objectID": "tutorials/analysis_andi.html",
    "href": "tutorials/analysis_andi.html",
    "title": "Benchmark: anomalous diffusion",
    "section": "",
    "text": "The main goal is to characterize anomalous diffusion processes that switch between diffusive states without any kind of prior konwledge. In this tutorial, we focus on inferring the anomalous diffusion exponent \\(\\alpha\\) at every time step, which naturally highlights potential changes in the behaviour along the trajectories. This allows us to obtain a deeper understanding of the underlying physical systems that drive the dynamics.\nIn the following analysis, we provide a thorough characterization of the model performance under various conditions and we show how to reproduce some figures of our paper."
  },
  {
    "objectID": "tutorials/analysis_andi.html#generate-the-data",
    "href": "tutorials/analysis_andi.html#generate-the-data",
    "title": "Benchmark: anomalous diffusion",
    "section": "Generate the data",
    "text": "Generate the data\nTo evaluate the different methods, we need a proper test set. We can generate one in the same way that we genereate the train set in the model training tutorial.\n\n\n\n\n\n\nNote\n\n\n\nSkip the data generation if you already have a test set!\n\n\n\n# OPTIONAL: create the test set.\n# Don't need to run this cell if it already exists.\nn_per_set = 12500\nmax_t = 200\ndim = 2 \ncps = [1, 2, 3, 4]\nds_fun = partial(create_andi_segmentation_dataset,\n                 max_t=max_t, dim=dim, noise=[0.], save=False)\ndatasets = [ds_fun(n_per_set, n_change_points=n_cp) for n_cp in cps]\ndataset = combine_datasets(datasets)\nn_change = f\"{min(cps)}_to_{max(cps)}\"\nsave_path = DATA_PATH/get_andids_fname(n_change, max_t, dim, \"test\")\ndataset.to_pickle(save_path)\n\nLoad the test set.\n\n# Skip this cell if you just generated it.\nn_change = \"1_to_4\"\nname = \"test\"\nds = load_dataset(n_change=n_change, dim=dim, name=name)"
  },
  {
    "objectID": "tutorials/analysis_andi.html#get-the-predictions",
    "href": "tutorials/analysis_andi.html#get-the-predictions",
    "title": "Benchmark: anomalous diffusion",
    "section": "Get the predictions",
    "text": "Get the predictions\nWe now perform the predictions of the trajectories store them in the dataframe to process them later. First, we compute the full-trajectory predictions. Then, we proceed with the segment-wise analysis. We split the trajectories and their predictions by the true changepoints. Then, we perform the prediction especifically for each segment with both the model and the TA-MSD method. We use the TA-MSD 2-10 to perform the evaluation.\nLet’s define a prediction function and a normalization function to simplify the code.\n\ndef predict_norm_sample(model, x):\n    \"Get the `model` prediction normalizing a single sample `x`.\"\n    xb = x.unsqueeze(0).to(default_device())\n    xb_norm = normalize(xb)[0]\n    return to_detach(model(xb_norm).squeeze())\n\ndef normalize(trajs):\n    \"Normalize a batch of trajectories.\"\n    bs, _, dim = trajs.shape\n    trajs -= trajs.mean(1, keepdim=True)\n    displ = trajs[:, 1:] - trajs[:, :-1]\n    std = displ.std(1, keepdim=True)\n    std = torch.where(std == 0., torch.ones_like(std), std)\n    displ /= std\n    trajs_norm = displ.cumsum(1)\n    trajs_norm = torch.cat([torch.zeros(bs, 1, dim, device=trajs.device),\n                            trajs_norm], axis=1)\n    return trajs_norm, std\n\nNow we can proceed to process the trajectories. In the following piece of code, we process every trajectory (outer loop). Then, we split it into segments with constant properties (inner loop), and we compute the mean absolute error (MAE) and the mean relative error with the three aforementioned approaches.\n\nmax_samples = 50000 # Subsample 50k trajectories\nsegment_data = []\n\nfor i, row in tqdm(ds[:max_samples].iterrows()):\n    x, y = row.x, row.y_exp.squeeze()\n    y_mod, cps = row.y_mod.squeeze(), row.cp\n    \n    # Predict over full trajectory\n    pred = predict_norm_sample(learn_exp.model, x.T)\n    \n    # Segment trajectory with true changepoints\n    split_x, split_pred = split_tensor(x.T, cps), split_tensor(pred, cps)\n    split_y, split_model = split_tensor(y, cps), split_tensor(y_mod, cps)\n    splits = zip(split_x, split_y, split_model, split_pred)\n    for j, (seg_x, seg_y, seg_model, pred_cut) in enumerate(splits):\n        # Prediction over full trajectory cut with true changepoints\n        mae = mean_absolute_error(pred_cut, seg_y)\n        \n        # Add noise to flat CTRW segments for numerical stability\n        if (seg_x - seg_x[0]).allclose(tensor(0.)):\n            seg_x += 0.1*torch.randn_like(seg_x)\n        \n        \n        # Prediction over segment\n        pred_segment = predict_norm_sample(learn_exp.model, seg_x - seg_x[0])\n        mae_segment = mean_absolute_error(pred_segment, seg_y)\n        \n        # Prediction over segment with TA-MSD\n        pred_tamsd = anomalous_exponent_tamsd(seg_x)\n        mae_tamsd = mean_absolute_error(pred_tamsd, seg_y[0])\n        \n        segment_data.append({'sample': i, 'segment_idx': j,\n                             'length': len(seg_y), 'x': seg_x, 'y': seg_y,\n                             'model': seg_model[0], 'pred_cut': pred_cut, \n                             'pred_segment': pred_segment,\n                             'pred_tamsd': pred_tamsd, 'mae': mae,\n                             'mae_segment': mae_segment,\n                             'mae_tamsd': mae_tamsd})\nds = pd.DataFrame.from_records(segment_data)\n\nUnlike in the normal diffusion case, we encounter some numerical instabilities with the methods when we provide them with the split segments. We purge all the broken predictions to proceed with the analysis.\n\nmask_full = ds.mae.apply(lambda x: torch.isnan(x).item())\nmask_tamsd = ds.mae_tamsd.apply(lambda x: torch.isnan(x).item())\nmask_seg = ds.mae_segment.apply(lambda x: torch.isnan(x).item())\nmask = (mask_full | mask_tamsd | mask_seg)\nds = ds[~mask]\n\nWe can save all the data for further posterior processing.\n\nds.to_pickle(DATA_PATH/'segment_analysis_alpha_test.pkl')"
  },
  {
    "objectID": "tutorials/analysis_andi.html#prediction-error",
    "href": "tutorials/analysis_andi.html#prediction-error",
    "title": "Benchmark: anomalous diffusion",
    "section": "Prediction error",
    "text": "Prediction error\nLet’s quantify the model performances by computing their MAE over full trajectories and trajectory segments.\n\nlengths = ds.length.unique().astype(int)\nlengths.sort()\n\nmetrics = ['mae', 'mae_segment', 'mae_tamsd']\nmetric_by_length = {m: {'mean': [], 'sem': [], 'global': None}\n                    for m in metrics}\n\nfor m in metrics:\n    means = [getattr(ds, m)[ds.length == l].mean()\n             for l in lengths]\n    sems = [getattr(ds, m)[ds.length == l].sem()\n            for l in lengths]\n        \n    metric_by_length[m]['mean'] = np.array(means)\n    metric_by_length[m]['sem'] = np.array(sems)\n    metric_by_length[m]['global'] = (\n        (getattr(ds, m)*ds.length).sum() / \n        ds.length.sum()\n    )\n\nSave this for later.\n\nname = \"mae_segment_length\"\ndata_path = (FIG_PATH/name).with_suffix(\".pkl\")\n\nwith open(data_path, 'wb') as f:\n    pickle.dump(metric_by_length, f, protocol=pickle.HIGHEST_PROTOCOL)\n\nLet’s see the overall MAE for each method.\n\n\nCode\nprint(f\"STEP: {metric_by_length['mae']['global']:.3f}\")\nprint(f\"STEP + segments: {metric_by_length['mae_segment']['global']:.3f}\")\nprint(f\"TA-MSD + segments: {metric_by_length['mae_tmsd']['global']:.3f}\")\n\n\nSTEP: 0.271\nSTEP + segments: 0.275\nTA-MSD + segments: 0.368\n\n\nSTEP outperforms the TA-MSD baseline, reducing the overall error by more than \\(25\\%\\). The advantage is significantly larger in short segments, as we see below.\n\n\nCode\nfig = plt.figure(figsize=(1.5*fig_size, fig_size))\nlengths = np.arange(10, 191)\nlabels = ['STEP', 'STEP + segments', 'TA-MSD + segments']\nfor i, m in enumerate(metric_by_length.keys()):\n    mean, sem = metric_by_length[m]['mean'], metric_by_length[m]['sem']\n    label = labels[i//2]# if i%2 == 0 else None\n    plt.plot(lengths, mean, linestyle='-', color=colors[i//2], label=label,\n                    zorder=10 if i==0 else -1)\n    plt.fill_between(lengths, mean - sem, mean + sem, color=colors[i//2], alpha=0.3)\nplt.grid(alpha=alpha_grid)\nplt.legend(fontsize=11)\nplt.tick_params(labelsize=14)\nplt.ylim([0.1, 0.75])\nplt.xlabel(\"Segment length\", fontsize=16)\nplt.ylabel(r\"$|\\alpha_{true} - \\alpha_{pred}|$\", fontsize=16);\n\n\n\n\n\nIn this case, the TA-MSD-based method does never reach the performance level of STEP, even in very long segments. This is in contrast to the Brownian motion benchmark, where the TA-MSD method attains a similar performance for the longest segments.\nAdditionally, in this case, feeding STEP with segments harms the performance in the shortest segments. As we have mentioned previously, doing this causes some numerical issues with the methods (both STEP and the TA-MSD). Regardless, the pre-segmented trajectories are never available in real scenarios."
  },
  {
    "objectID": "tutorials/analysis_andi.html#error-by-anomalous-diffusion-model",
    "href": "tutorials/analysis_andi.html#error-by-anomalous-diffusion-model",
    "title": "Benchmark: anomalous diffusion",
    "section": "Error by anomalous diffusion model",
    "text": "Error by anomalous diffusion model\nThe anomalous diffusion models that we consider describe very different behaviours. The deviation from normal diffusion has different sources in each of them and, therefore, their anomalous diffusion exponent \\(\\alpha\\) depends on different phenomena.\nHence, it is reasonable to expect the underlying anomalous diffusion model of each segment to play a key role in the characterization. Furthermore, every model has a different range for \\(\\alpha\\):\n\nAnnealed transit time (ATTM) with \\(\\alpha\\in\\left[0.05, 1\\right]\\).\nContinuous time random walk (CTRW) with \\(\\alpha\\in\\left[0.05, 1\\right]\\).\nFractional Brownian motion (FBM) with \\(\\alpha\\in\\left[0.05, 1.95\\right]\\).\nLévy Walk (LW) with \\(\\alpha\\in\\left[1.05, 2\\right]\\).\nScaled Brownian motion (SBM) with \\(\\alpha\\in\\left[0.05, 2\\right]\\).\n\nThe wider the \\(\\alpha\\) range, the larger the errors can become. Let’s look at the MAE for each method.\n\nmae_by_model = [ds[(ds.model == m)].mae.mean()\n                for m in MODEL_DATA.keys()]\n\n\n\nCode\nx = np.arange(5)\nplt.bar(x, mae_by_model, color=colors[0], width=0.6)\nplt.grid(axis='y', alpha=alpha_grid)\nplt.ylabel('MAE', fontsize=16)\nplt.xticks(x, [MODEL_DATA[n]['name'].upper() for n in x])\nplt.tick_params(axis='x', labelsize=16)\nplt.tick_params(axis='y', labelsize=14)\n\n\n\n\n\nCTRW, FBM and LW have similar MAE. Surprisingly, FBM holds the lowest error while having one of the largest ranges for \\(\\alpha\\). Then, ATTM and SBM are clearly the hardest models to characterize, as their MAE is between \\(50\\%\\) to \\(100\\%\\) larger than the other methods.\nIn SBM, as we will see in the next tutorial, \\(\\alpha\\) is related to the ageing of the diffusion coefficient. This means that we need long segments to correctly characterize \\(\\alpha\\).\n\n\n\n\n\n\nNote\n\n\n\nSBM was also found to be the hardest model to characterize in the AnDi Challenge.\n\n\nLet’s bring this study further to get a better idea about the sources of errors in all the models, such as ATTM."
  },
  {
    "objectID": "tutorials/analysis_andi.html#error-by-diffusion-model-and-localization-noise",
    "href": "tutorials/analysis_andi.html#error-by-diffusion-model-and-localization-noise",
    "title": "Benchmark: anomalous diffusion",
    "section": "Error by diffusion model and localization noise",
    "text": "Error by diffusion model and localization noise\nLet’s study the behaviour of STEP for each diffusion model in more detail and, at the same time, study its resilience to localization noise.\n\n# Optional: load the test set if it is not in memory\nds = load_dataset(n_change=\"1_to_4\", dim=dim, name=\"test\")\n\nTo make the computation more bearable, we work with a fraction of our full test set.\n\nds = ds.sample(frac=0.25, random_state=0).reset_index(drop=True)\n\n\nds['y'] = ds['y_exp'].apply(torch.squeeze)\nds['model'] = ds['y_mod'].apply(torch.squeeze)\nds = ds.drop(columns=['y_mod', 'y_exp', 'models', 'exps', 'noise'])\n\n\nProcess the trajectories\nSimilar to the Brownian motion analysis, we will process the trajectories at various noise levels.\nHere, we sample \\(\\sigma_{\\text{noise}}\\in[10^{-5}, 10^2]\\) uniformly in log space.\n\nnoise_samples = 128\nnoise_max, noise_min = 2, -5\nnoise_range = noise_max - noise_min\nnoise_traj = torch.rand(ds.shape[0], noise_samples)*noise_range + noise_min\n\nAs in the previous cases, we can compare the predictions of STEP with the TA-MSD baseline.\n\ndef predict(model, x):\n    \"Get prediction of `model` on batch `x`.\"\n    return to_detach(model(x.to(default_device()))).squeeze()\n\n\nshape = (ds.shape[0], max_t, noise_traj.shape[1])\npred_by_noise = torch.zeros(shape) \npred_tamsd_by_noise = torch.zeros(shape)\n\nfor i, (x, cps) in tqdm(ds[['x','cp']].iterrows()):\n    noise = torch.randn(noise_samples, *x.T.shape)*10**noise_traj[i]\n    noisy_x = x.T.unsqueeze(0) + noise.unsqueeze(-1).unsqueeze(-1)\n    noisy_x, std = normalize(noisy_x)\n    split_x = split_tensor(noisy_x.transpose(1, 0), cps)\n    \n    pred_by_noise[i] = predict(learn_exp.model, noisy_x).T\n    \n    pred_tamsd = []\n    for seg_x in split_x:\n        seg_x, _ = normalize(seg_x.transpose(1, 0))\n        ones = torch.ones(seg_x.shape[1])\n        pred_tamsd.append(torch.stack([ones*anomalous_exponent_tamsd(s)\n                                       for s in seg_x]))\n        \n    pred_tamsd_by_noise[i] = torch.cat(pred_tamsd, axis=-1).T\npredictions = dict(zip(['full', 'tamsd'],\n                       [pred_by_noise, pred_tamsd_by_noise]))\n\nWith the predictions, we can compute the error performed at every time step as a function of \\(\\sigma_{\\text{noise}}\\) and the diffusion model independently.\nTherefore, we start by obtaining the diffusion model and noise of every trajectory at every time step.\n\ny = torch.stack([t for t in ds['y'].values])\nmodel = torch.stack([t for t in ds['model'].values])\nrel_noise = noise_traj.unsqueeze(1) + torch.zeros_like(y.unsqueeze(-1)) \nmodel = model.unsqueeze(-1) + torch.zeros_like(rel_noise)\n\nNow we can compute the pointwise errors of the full test set with random noise.\n\nerrors = {k: y.unsqueeze(-1) - p for k, p in predictions.items()}\nbins_noise = torch.linspace(rel_noise.min(), rel_noise.max(), 100)\n\n\n\nOverall performance\nWe can get a good idea about the error sources by looking at the predicted vs true \\(\\alpha\\) values for each anomalous diffusion model.\nFor this, we need a target tensor with the same shape as our predictions for all noise levels.\n\ny_ext = y.unsqueeze(-1) + torch.zeros_like(model)\ny_ext.shape\n\ntorch.Size([49994, 200, 128])\n\n\nAnd it is useful to have a mapping between model names and their integer index.\n\nmodel_keys = {v['name']: k for k, v in MODEL_DATA.items()}\nmodel_keys\n\n{'attm': 0, 'ctrw': 1, 'fbm': 2, 'lw': 3, 'sbm': 4}\n\n\nNow we can define the different noise intervals at which we wish to study the models. We consider \\(\\sigma_{\\text{noise}}\\in\\left\\{[10^{-5}, 10^{-4}], [10^{-2}, 10^{-1}], [10^{-1}, 10^{0}]\\right\\}\\). The first interval is a quasy-noiseless regime, the second is moderate noise and the third is very high noise.\n\npred_vs_true_by_model = {}\nnoise_ranges = [(-5, -4), (-2, -1), (-1, 0)]\nbins = (0, 2, 41)\n\nLet’s compute the 2D histograms of \\(\\alpha_{\\text{pred}}\\) vs \\(\\alpha_{\\text{true}}\\).\n\npreds_full = predictions['full']\nfor m in tqdm(list(model_keys.keys()) + ['all']):\n    mask_model = (model == model_keys[m] if m != 'all'\n                  else torch.ones_like(model, dtype=bool))\n    model_histograms = []\n    for (low, high) in noise_ranges:\n        mask_noise = (low &lt;= rel_noise) & (rel_noise &lt; high)\n        mask = mask_model & mask_noise\n        hist, true_e, pred_e = np.histogram2d(y_ext[mask].numpy(),\n                                              preds_full[mask].numpy(),\n                                              bins=[np.linspace(*bins)+1e-3,\n                                              np.linspace(*bins[:2], 41)])\n        model_histograms.append(hist)\n    pred_vs_true_by_model[m] = {'hist': model_histograms,\n                                'true_edges': true_e, \n                                'pred_edges': pred_e}\n\n\n\n\nSave them for later.\n\nfig_name = \"pred_vs_true_models\"\nplot_data = (pred_vs_true_by_model, noise_ranges, bins_by_model)\nwith open(FIG_PATH/f'{fig_name}.pkl', 'wb') as f:\n    pickle.dump(plot_data, f, protocol=pickle.HIGHEST_PROTOCOL)\n\n\n\nCode\nfig, axes = plt.subplots(3, 5, figsize=(6*fig_size, 3*fig_size),\n                         constrained_layout=True)\nticks = (np.arange(0, 41, 20), [0, 1, 2])\nticksize = 16\nfontsize = 20\nnoise_ranges = [\"$[10^{-5}, 10^{-4})$\",\n                \"$[10^{-2}, 10^{-1})$\",\n                \"$[10^{-1}, 10^{0})$\"]\nvmax = {'attm': [0.9, 0.9, 0.9],\n        'ctrw': [0.8, 0.9, 0.8],\n        'fbm':  [0.3, 0.3, 0.5],\n        'lw':   [0.6, 0.6, 0.6],\n        'sbm':  [0.9, 0.9, 1]}\n\nfor m, data in pred_vs_true_by_model.items():\n    if m == 'all': continue\n    m_axes = axes[:, model_keys[m]]\n    hist= data['hist']\n    for i, ax in enumerate(m_axes):\n        shape = hist[i].shape\n        ax.pcolor(hist[i].T/hist[i].max(), vmin=0, vmax=vmax[m][i],\n                  cmap=cmap_hist1, rasterized=True)\n        \n        if i == 0:\n            ax.set_title(m.upper(), fontsize=fontsize)\n            ax.tick_params(labeltop=False)\n        if i == 1:\n            ax.tick_params(labeltop=False)\n            \n        if i == 2:\n            ax.set_xticks(*ticks)\n            ax.set_xlabel(r'$\\alpha_{true}$', fontsize=fontsize)\n            ax.tick_params(labeltop=False, labelbottom=True)\n        else:\n            ax.set_xticks([])\n            \n        if model_keys[m] == 0: \n            ax.set_ylabel(r'$\\alpha_{pred}$', fontsize=fontsize)\n            ax.set_yticks(*ticks)\n        else:\n            ax.set_yticks([])\n        \n        ax.tick_params(labelsize=ticksize);\n        \n    if m == 'sbm':\n        for ax, noise in zip(m_axes, noise_ranges):\n            ax.text(42, 20, fr\"$\\sigma_{{noise}} \\in$\" + noise, fontsize=fontsize)\n\n\n\n\n\nAs expected, we observe a very nice \\(\\alpha_{\\text{pred}}\\) vs \\(\\alpha_{\\text{true}}\\) relationship for FBM and LW segments.\nThere is a clear tendency for STEP to predict \\(\\alpha\\approx0.8\\) for SBM segments which is enhanced with noise. This is indicative that the model struggles to identify any clear behaviour and defaults to a quasi Brownian motion prediction.\nIn CTRW segments we find a similar pattern, where the model predicts \\(\\alpha\\approx0.25\\), corresponding to nearly immobile particles. CTRW trajectories are characterized by immobilization with jumps at random times. In short segments, it is very likely that no jumps are shown and, thus, the model sees a static particle.\nTo a lesser extent, we observe a tendnency for ATTM trajectories to predict \\(\\alpha\\approx1\\). ATTM trajectories are characterized by Brownian motion segments with random diffusion coefficients that change at random times. In short ATTM segments, it is very likely that there are no diffusion coefficient changes. Therefore, STEP only sees a pure Brownian motion segment for which the prediction of \\(\\alpha\\approx1\\) is correct.\n\n\nMAE as function of \\(\\sigma_{\\text{noise}}\\)\nNow we can look at the MAE of STEP and the TA-MSD baseline as function of the localization noise.\n\nnoise_err, noise_err_std, x_err, counts = [], [], [], []\nfor low, high in tqdm(zip(bins_noise[:-1], bins_noise[1:])):\n    mask = (rel_noise &gt;= low) & (rel_noise &lt;= high)\n    x.append((low + high)/2)\n    counts.append(mask.float().sum())\n    noise_err.append(tensor([err[mask & ~err.isnan()].abs().mean()\n                             for err in errors.values()]))\n    noise_err_std.append(tensor([err[mask & ~err.isnan()].abs().std()\n                                 for err in errors.values()]))\n    \nnoise_err = torch.stack(noise_err)\nnoise_err_std = torch.stack(noise_err_std)\nx_err = torch.stack(x_err)\ncounts = torch.stack(counts)\n\n\n\n\nWe can go a step further and compute the MAE for each diffusion model separately and as function of the noise.\n\nerrors_model = {k: errors['full'][model == i] for k, i in model_keys.items()}\n\n\nmae_model_by_noise = {}\nfor m, i in model_keys.items():\n    mae = []\n    noise_model = rel_noise[model == i]\n    for low, high in tqdm(zip(bins_noise[:-1], bins_noise[1:])):\n        mask = (noise_model &gt;= low) & (noise_model &lt;= high)\n        mae.append(errors_model[m][mask].abs().mean())\n    mae_model_by_noise[m] = mae\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nfig, ax = plt.subplots(1, 2, figsize=(2.5*fig_size, fig_size), constrained_layout=True)\n\nlabels = ['STEP', 'TA-MSD + segments']\nidx = [0, 3]\nsem = noise_err_std/counts.sqrt().unsqueeze(-1)\nfor i, (err, s) in enumerate(zip(noise_err.T[idx], sem.T[idx])):\n    ax[0].semilogx(10**x_err, err, '-', linewidth=3., color=colors[2*i], label=labels[i])\n    ax[0].fill_between(10**x_err, err - s, err + s, color=colors[2*i], alpha=0.3)\nax[0].legend(fontsize=14)\nax[0].set_xlabel(r\"$\\sigma_{noise}$\", fontsize=16)\nax[0].set_ylabel(\"MAE\", fontsize=16)\nax[0].set_xlim([2e-5, 50])\n\ndx = bins_noise[1] - bins_noise[0]\nx_noise_model = bins_noise[:-1] + dx\nfor i, (m, mae) in enumerate(mae_model_by_noise.items()):\n    ax[1].semilogx(10**x_noise_model, mae, linewidth=2, color=colors[i], label=m.upper())\nax[1].set_xlim([10**(-3.5), 6])\nax[1].legend(fontsize=14)\nax[1].set_xlabel(r\"$\\sigma_{noise}$\", fontsize=16)\nax[1].set_yticklabels([])\n\nfor a in ax:\n    a.tick_params(labelsize=14)\n    a.grid(alpha=alpha_grid)\n\n\n\n\n\nLet’s save the data of the figures to process them later.\n\nfig_name = \"noise_analysis_alpha\"\nplot_path = (FIG_PATH/fig_name).with_suffix(\".pkl\")\nplot_data = (noise_err, noise_err_std, x, counts)\nwith open(plot_path, 'wb') as f:\n    pickle.dump(plot_data, f, protocol=pickle.HIGHEST_PROTOCOL)\n\nfig_name = \"noise_analysis_mae_models\"\nplot_path = (FIG_PATH/fig_name).with_suffix(\".pkl\")\nplot_data = (mae_model_by_noise, bins_noise)\nwith open(plot_path, 'wb') as f:\n    pickle.dump(plot_data, f, protocol=pickle.HIGHEST_PROTOCOL)"
  },
  {
    "objectID": "tutorials/analysis_andi.html#generate-the-data-1",
    "href": "tutorials/analysis_andi.html#generate-the-data-1",
    "title": "Benchmark: anomalous diffusion",
    "section": "Generate the data",
    "text": "Generate the data\nIn order to obtain a better insight about the strengths of the methods, we test them in trajectories with one single changepoint. Furthermore, we restrict ourselves to FBM trajectories, which has been the anomalous diffusion model for which our methods provided the best results.\nIn this way, we study how the changepoint position and difference between \\(\\alpha\\) in consecutive segments affects the performance.\n\nds = create_segmentation_dataset(40000, dim=2, models=[2], noise=[0.], save=False)"
  },
  {
    "objectID": "tutorials/analysis_andi.html#get-the-predictions-1",
    "href": "tutorials/analysis_andi.html#get-the-predictions-1",
    "title": "Benchmark: anomalous diffusion",
    "section": "Get the predictions",
    "text": "Get the predictions\nLet’s define some helping functions to keep our code clean.\n\ndef make_batch(df, i, bs, col='x'):\n    \"Return a batch of samples from df.\"\n    samples = [x.transpose(-1, 0) for x in ds.loc[i*bs:(i+1)*bs-1, col]]\n    return torch.stack(samples, dim=0)\n\ndef predict_norm(model, x):\n    \"Get the `model` prediction normalizing the batch `x`.\"\n    x_norm = normalize(x.to(default_device()))[0]\n    return to_detach(model(x_norm).squeeze())\n\nLet’s gooo.\n\nbs = 100\nn_batch = np.ceil(ds.shape[0]/bs).astype(int)\nfor i in tqdm(range(n_batch)):\n    xb = make_batch(ds, i, bs)\n    pred = predict_norm(learn_exp.model, xb)\n    ds.loc[i*bs:(i+1)*bs-1, 'pred'] = np.array([p for p in pred],\n                                               dtype=object)"
  },
  {
    "objectID": "tutorials/analysis_andi.html#overall-performance-1",
    "href": "tutorials/analysis_andi.html#overall-performance-1",
    "title": "Benchmark: anomalous diffusion",
    "section": "Overall performance",
    "text": "Overall performance\nLet’s compute the Jaccard index (JI) using the STEP predictions and the \\(\\alpha\\) estimation with the TA-MSD.\nWe need to define a function to compute \\(\\alpha\\) along the trajectory with a sliding window.\n\ndef swin_alpha_tamsd(x, win_size=10):\n    \"Computes the anomalous exponent with a sliding window over x.\"\n    alphas = []\n    for i in range(len(x) - win_size):\n        alpha = anomalous_exponent_tamsd(x[i:i + win_size],\n                                         t_lag=np.arange(2, win_size//2))\n        alphas.append(alpha)\n    return np.array(alphas)\n\nTo ease the code readability, we define a function to combine two dictionaries together (adhoc for our purposes).\n\ndef merge_dict(dict_1, dict_2):\n    merge = {}\n    for k, v1 in dict_1.items():\n        v2 = dict_2.get(k, [])\n        if isinstance(v1, Iterable) and isinstance(v2, Iterable):\n            merge[k] = [*v1, *v2]\n        elif isinstance(v1, Iterable):\n            merge[k] = [*v1, v2]\n        elif isinstance(v2, Iterable):\n            merge[k] = [v1, *v2]\n        else:\n            merge[k] = [v1, v2]\n    return merge\n\nNow we process every trajectory and retrieve the changepoints with ruptures using both inputs.\n\nmethod_pen = {'pred': 2., 'tamsd': 8.}\nwin_size = 30\nmethods = list(method_pen.keys())\nthreshold = 20\n\nmetrics_method = {m: {} for m in methods}\nfor i, row in tqdm(ds.iterrows()):\n    traj = normalize(row.x.T.unsqueeze(0))[0]\n    pred, true_cp = row.pred.numpy(), row.cp.numpy()\n    alphas_tamsd = swin_alpha_tamsd(traj.squeeze(), win_size=win_size)\n\n    for m in methods:\n        seg_data = (pred if m == 'pred' \n                    else alphas_tamsd if m == 'tamsd'\n                    else None)\n        pred_cp = ruptures_cp(seg_data, pen=method_pen[m], min_size=5)\n        if m == 'tamsd':\n            # Add half window size to the prediction from TA-MSD\n            pred_cp = [p + win_size//2 for p in pred_cp]\n        metrics = evaluate_cp_prediction(true_cp, pred_cp,\n                                         changepoint_threshold=threshold)\n        metrics_method[m] = merge_dict(metrics, metrics_method[m])\n\n        for k, v in metrics.items():\n            if metrics['tp']:\n                ds.loc[i, f'cp_{m}_{k}'] = v[0] if k == 'sq_error' else v\n            else:\n                ds.loc[i, f'cp_{m}_{k}'] = -1 if k == 'sq_error' else v\n\nNow we can compute the overall JI and MSE for both approaches over the whole test set.\n\nmethod_mse, method_j_idx = {}, {}\nfor m, v in metrics_method.items():\n    method_mse[m] = np.mean(v['sq_error'])\n    tp, fp, fn = np.sum(v['tp']), np.sum(v['fp']), np.sum(v['fn'])\n    method_j_idx[m] = jaccard_index(tp, fp, fn)\n\n\n# code-fold: true\nprint(\"Jaccard index:\")\nfor m, ji in method_j_idx.items():\n    print(f\"  {m}: {ji:.3f}\")\nprint(\"MSE:\")\nfor m, ji in method_mse.items():\n    print(f\"  {m}: {ji:.3f}\")\n\nJaccard index:\n  pred: 0.515\n  tamsd: 0.297\nMSE:\n  pred: 35.011\n  tamsd: 71.276\n\n\nRunning the changepoint detection algorithm over the STEP predictions provides a massive advantage with respect to the sliding window TA-MSD baseline. We reduce the changepoint prediction error by about \\(30\\%\\) and we cut the MSE by half.\nHowever, the changepoint detection task for \\(\\alpha\\) proves to be significantly more challenging than for \\(D\\), where we achieve mean JI over 0.8, as we saw in the Brownian motion benchmark."
  },
  {
    "objectID": "tutorials/analysis_andi.html#difference-between-segments",
    "href": "tutorials/analysis_andi.html#difference-between-segments",
    "title": "Benchmark: anomalous diffusion",
    "section": "Difference between segments",
    "text": "Difference between segments\nJust like we did for the diffusion coefficient, we can look at how the jaccard index behaves as function of the difference between consecutive segments.\nWe start by computing the difference between consecutive \\(\\alpha\\) in each trajectory.\n\nds['cp'] = ds.cp.apply(lambda x: x[0].item())\nds['alpha_diff'] = ds.exps.apply(lambda x: round((x[1] - x[0]).item(), 2))\n\nNow we can compute the metrics.\n\ndifferences = np.unique(ds.alpha_diff)\nj_idx_by_diff = {m: [] for m in methods}\nfor diff in differences:\n    mask = ds.alpha_diff == diff\n    for m in methods:\n        tp = ds.loc[mask, f'cp_{m}_tp'].sum()\n        fp = ds.loc[mask, f'cp_{m}_fp'].sum()\n        fn = ds.loc[mask, f'cp_{m}_fn'].sum()\n        j_idx_by_diff[m].append(jaccard_index(tp, fp, fn))\n\n\n\nCode\nmethod_color = {'pred': colors[0], 'displ': colors_light[3], 'tamsd': colors[2]}\nmethod_label = {'pred': 'KCPD + STEP', 'displ': 'KCPD + displ', 'tamsd': 'KCPD + TA-MSD'}\nmethod_ls = {'pred': 'solid', 'displ': 'dashed', 'tamsd': 'dashed'}\n\nfig = plt.figure(figsize=(1.4*fig_size, fig_size))\nfor m in methods:\n    plt.plot(differences, j_idx_by_diff[m], linewidth=linewidth, label=method_label[m],\n             color=method_color[m], linestyle=method_ls[m])\nplt.legend(fontsize=14)\nplt.grid(alpha=alpha_grid)\nplt.xlim([-2.2, 2.2])\nplt.xticks([-2, -1, 0, 1, 2])\nplt.ylim([-0.05, 1.05])\nplt.yticks([0., 0.5, 1.])\nplt.xlabel(r\"$\\alpha_2 - \\alpha_1$\", fontsize=16)\nplt.ylabel(\"Jaccard index\", fontsize=16)\nplt.tick_params(labelsize=14)\n\n\n\n\n\n\nChange point position\n\nbins_cp = np.arange(10, 200, 10)\nj_idx_by_position = {m: [] for m in methods}\nfor low, high in zip(bins_cp[:-1], bins_cp[1:]):\n    mask = (low &lt;= ds.cp) & (ds.cp &lt; high)\n    for m in methods:\n        tp = ds.loc[mask, f'cp_{m}_tp'].sum()\n        fp = ds.loc[mask, f'cp_{m}_fp'].sum()\n        fn = ds.loc[mask, f'cp_{m}_fn'].sum()\n        j_idx_by_position[m].append(jaccard_index(tp, fp, fn))\n\n\n\nCode\nfig = plt.figure(figsize=(1.4*fig_size, fig_size))\nfor m in methods:\n    plt.plot(j_idx_by_position[m], linewidth=linewidth, label=method_label[m],\n              color=method_color[m], linestyle=method_ls[m])\nx_tick_idx = np.array([0, 9, 17])\nplt.xticks(x_tick_idx, \n           [f'{low}-{high}' for low, high in zip(bins_cp[x_tick_idx], bins_cp[x_tick_idx+1])])\nplt.grid(alpha=alpha_grid)\nplt.legend(fontsize=14)\nplt.ylim([-0.05, 1.05])\nplt.yticks([0., 0.5, 1.])\nplt.xlabel(\"Changepoint position\", fontsize=16)\nplt.tick_params(labelsize=14)"
  },
  {
    "objectID": "tutorials/anomalous_from_normal.html",
    "href": "tutorials/anomalous_from_normal.html",
    "title": "Anomalous diffusion from normal diffusion",
    "section": "",
    "text": "The main goal of this tutorial is to show how we can detect the emergence of anomalous diffusion with an accurate description of the diffusion coefficient through time. This kind of analysis provides us with much richer information about the underlying physical processes in the system than methods that simply extract a global anomalous diffusion exponent from the trajectories."
  },
  {
    "objectID": "tutorials/anomalous_from_normal.html#generate-the-data",
    "href": "tutorials/anomalous_from_normal.html#generate-the-data",
    "title": "Anomalous diffusion from normal diffusion",
    "section": "Generate the data",
    "text": "Generate the data\nLet’s generate SBM trajectories for a couple of anomalous diffusion exponents \\(\\alpha=0.1, 0.5\\).\nSBM is model number 4, following the AnDi datasets convention. We can see that in the MODEL_DATA dictionary.\n\nMODEL_DATA\n\n{0: {'name': 'attm', 'exps': (0.05, 1.0)},\n 1: {'name': 'ctrw', 'exps': (0.05, 1.0)},\n 2: {'name': 'fbm', 'exps': (0.05, 1.95)},\n 3: {'name': 'lw', 'exps': (1.05, 2.0)},\n 4: {'name': 'sbm', 'exps': (0.05, 2.0)}}\n\n\nFor this analysis, we will create 3000 trajectories for each \\(\\alpha\\) of 200 time steps.\n\nn_traj, max_t, exponents, models, dim = 6000, 200, np.array([0.1, 0.5]), [4], 2\ntrajs = create_trajectories(n_traj, max_t, exponents, models, dim, noise=None)\ntrajs = tensor(trajs[:, 2:].reshape((n_traj, dim, max_t)).transpose(0, 2, 1))"
  },
  {
    "objectID": "tutorials/anomalous_from_normal.html#extract-the-diffusion-coefficient",
    "href": "tutorials/anomalous_from_normal.html#extract-the-diffusion-coefficient",
    "title": "Anomalous diffusion from normal diffusion",
    "section": "Extract the diffusion coefficient",
    "text": "Extract the diffusion coefficient\nLet’s predict the diffusion coefficient for these trajectories. We will compare the results obtained with STEP with the diffusion coefficient obtained from a linear fit of the time-averaged mean squared displacement (TA-MSD) over a sliding window of 20 time steps along the trajectories.\nLet’s start with STEP. In order to speed things up, we can group the trajectories in batches.\n\nbs = 128\nn_batch = np.ceil(n_traj/bs).astype(int)\nbatches = [trajs[i*bs:(i+1)*bs] for i in range(n_batch)]\n\n\npreds_step = [to_detach(learn_diff.model(xb.cuda()).squeeze()) for xb in batches]\npreds_step = torch.cat(preds_step, axis=0)\n\nNow we can proceed with the TA-MSD fit over a sliding window.\n\ndef swin_D_tmsd(x, win_size=20):\n    \"Computes the anomalous exponent with a sliding window over x.\"\n    return np.array([diffusion_coefficient_tamsd(x[i:i + win_size], t_lag=[1, 2])\n                     for i in range(len(x) - win_size)])\n\n\npreds_tamsd = tensor([swin_D_tmsd(t) for t in trajs])  # Can take a couple of minutes\n\nLet’s see the results!\n\n\nCode\nfrom matplotlib.lines import Line2D\n\nidx = n_traj // 2\nsbm01_step = 10**(preds_step[:idx]).mean(0)\nsbm01_tamsd = preds_tamsd[:idx].mean(0)\nsbm05_step = 10**(preds_step[idx:]).mean(0)\nsbm05_tamsd = preds_tamsd[idx:].mean(0)\n\nx_step = np.arange(max_t) + 1\nwin_size = max_t - sbm01_tamsd.shape[0]\nx_tamsd = np.arange(win_size//2, max_t - win_size//2)\n\n# ALPHA = 0.1\nfor t in preds_step[:5, :]:\n    t = 10**t\n    t = t/t[0]\n    plt.loglog(x_step, t, c=colors[0], alpha=0.2)\n    \nplt.loglog(x_step, sbm01_step/sbm01_step[0], c=colors[0], label=r'$\\alpha = 0.1$', marker='o', ms=2, lw=0)\nplt.loglog(x_step, sbm01_step/sbm01_step[0], c=colors[0], alpha=0.5)\nplt.loglog(x_tamsd, sbm01_tamsd/sbm01_tamsd[0]/1.7, c=colors[0])  # Rescale by 1/1.7 to bring lines close\n    \n# ALPHA = 0.5\nfor t in preds_step[-5:, :]:\n    t = 10**t\n    t = t/t[0]\n    plt.loglog(x_step, t, c=colors[1], alpha=0.2)\n\nplt.loglog(x_step, sbm05/sbm05[0], c=colors[1], marker='o', ms=2, lw=0)\nplt.loglog(x_step, sbm05/sbm05[0], c=colors[1], alpha=0.5)\nplt.loglog(x_tamsd, sbm05_tamsd/sbm05_tamsd[0], c=colors[1])\n\n# Analytical scaling\nalpha = 0.1\ninit, end = 20, 90\nplt.plot(np.arange(init, end), 2.3*np.arange(init, end)**(0.1 - 1), c=colors[0], ls='--')\nplt.plot(np.arange(init, end), 2*np.arange(init, end)**(0.5 - 1), c=colors[1], ls='--')\n\n\nplt.xlabel(\"Time (s)\", fontsize=16)\nplt.ylabel(\"$D$ \" + D_units, fontsize=16)\n\nplt.grid(alpha=alpha_grid)\nlegend_elements = [Line2D([0], [0], color=colors[0], lw=10, label=r'$\\alpha = 0.1$'),\n                   Line2D([0], [0], color=colors[1], lw=10, label=r'$\\alpha = 0.5$'),\n                   Line2D([0], [0], color=\"k\", lw=2, linestyle=\"dashed\", label=r'Expected'),\n                   Line2D([0], [0], color=\"k\", marker='o', lw=2, markersize=8, label=r'STEP'),\n                   Line2D([0], [0], color=\"k\", lw=2, label=r'TA-MSD')]\nplt.legend(handles=legend_elements, fontsize=14)\n\nplt.tick_params(direction='in')\nplt.tick_params(which='minor', direction='in')\nplt.tick_params(labelsize=14);\n\n\n\n\n\nWe see that, even though our model has not been trained to predict smooth changes in \\(D\\), it can capture the phenomenon on average. Both STEP and the TA-MSD with a sliding window allow us to recover the expected power-law scaling \\(D(t)\\propto t^{\\alpha}\\).\nFinally, we can save our results for the future.\n\nfile_name = \"preds_sbm\"\ndata_path = DATA_PATH/file_name\nwith open(data_path.with_suffix('.pkl'), 'wb') as f:\n    pickle.dump({\"step\": preds_step, \"tamsd\": preds_tamsd}, f, protocol=pickle.HIGHEST_PROTOCOL)"
  },
  {
    "objectID": "tutorials/model_training.html",
    "href": "tutorials/model_training.html",
    "title": "Model training",
    "section": "",
    "text": "When training machine learning models to characterize diffusion processes, we need to keep in mind that these should be robust to the adversities related with the typical experimental conditions.\nA key factor to consider, is the localization precision of the experiment or localization noise. Here, we simulate it as white noise with standard deviation \\(\\sigma_{\\text{noise}}\\) that we add to the trajectories. This also acts as a form of data augmentation and helps our model generalize better.\n\nclass LocalizationNoise(ItemTransform):\n    \"Add localization noise to the trajectories.\"\n    def __init__(self, noise_lvls): self.noise_lvls = tensor(noise_lvls)\n    def encodes(self, sample):\n        x, y = sample\n        idx = torch.randint(self.noise_lvls.shape[0], (1,))\n        noise = self.noise_lvls[idx]\n        noisy_x = x + 10**(noise)*torch.randn_like(x)\n        return noisy_x - noisy_x[0], y\n\nWith LocalizationNoise, we add noise to every trajectory in a training batch. It takes noise_lvls as input, which is a list of the different \\(\\sigma_{\\text{noise}}\\) to consider in \\(\\log_{10}\\) scale. This way, we can choose to randomly add different levels of noise to each trajectory."
  },
  {
    "objectID": "tutorials/model_training.html#generate-the-data",
    "href": "tutorials/model_training.html#generate-the-data",
    "title": "Model training",
    "section": "Generate the data",
    "text": "Generate the data\nIn order to train our models, we need to generate a data set. As we explain in the data docs, our trajectories contain different numbers of changepoints. To do so, we generate separate data sets with a fixed number of change points and combine them together.\nWe have found that training our models with 2 to 5 segments (1 to 4 changepoints) is more than enough to generalize well to trajectories with an abritrary number of segments.\n\n\n\n\n\n\nNote\n\n\n\nSkip this section if you already have a data set to train!\n\n\n\nn_per_set = 12000\nmax_t = 200\ndim = 2\nDs = np.logspace(-3, 3, 1000) \ncps = [1, 2, 3, 4]\nds_fun = partial(create_bm_segmentation_dataset,\n                 max_t=max_t, dim=dim, Ds=Ds, save=False)\n\n\ndatasets = [ds_fun(n_per_set, n_change_points=n_cp) for n_cp in cps]\ndataset = combine_datasets(datasets)\n\nn_change = f\"{min(cps)}_to_{max(cps)}\"\nsave_path = DATA_PATH/get_bmds_fname(n_change, max_t, dim, \"train\")\ndataset.to_pickle(save_path)"
  },
  {
    "objectID": "tutorials/model_training.html#train-the-model",
    "href": "tutorials/model_training.html#train-the-model",
    "title": "Model training",
    "section": "Train the model",
    "text": "Train the model\nWe train our models using the fastai library to handle the training loop. To do so, we combine the essential blocks of any training loop:\n\nA model to train\nA data loader\nA loss function\nAn optimization algorithm (we use the default Adam)\n\nInto a Learner object. We can tweak all sorts of parameters and add, for example, data agumentation transforms, such as the LocalizationNoise we have defined above.\n\n\n\n\n\n\nNote\n\n\n\nFor anyone starting with machine learning, we recommend checking the fastai courses and their book, which is also available in open source.\n\n\nWe start by creating the data loaders that will take the data from above. Since we are working with Brownian motion trajectories, we set bm=True and forget about the target, as it is always the diffusion coefficient. Actually, rather than predicting the actual value of the diffusion coefficient, we will work with its logarithm, so we set tfm_y=torch.log10. This allows us to mantain a constant relative error across all the orders of magnitude. Finally, we set the device to be the default_device, which is the first GPU, in case there is one, or the CPU.\n\ndim = 2\ndls = get_segmentation_dls(dim=dim, n_change='1_to_4', name='train',\n                           tfm_y=torch.log10, bm=True)\ndls.device = default_device()\n\nWe can add the localization noise transform to our data. We will leave some noiseless trajectories (\\(\\log_{10}\\sigma_{\\text{noise}}=-\\infty\\)) and then take noise amplitudes from \\(10^{-6}\\) to \\(10^{1}\\).\n\nnoise_levels = torch.cat([-tensor([float('inf')]), torch.linspace(-6, 1, 8)])\ndls.add_tfms(LocalizationNoise(noise_levels), 'after_item')\n\nFor the machine learning model, we have found that our XResAtnn model works the best and trains rather fast.\n\nmodel = XResAttn(dim, n_class=1, stem_szs=(64,), conv_blocks=[1, 1, 1],\n                 block_szs=[128, 256, 512], pos_enc=False, \n                 n_encoder_layers=4, dim_ff=512, nhead_enc=8,\n                 linear_layers=[], norm=False, yrange=(-3.1, 5.1))\nmodel.to(default_device())\n\nFinally, we put all together in a Leaner. We will use the mean absolute error loss, or \\(L_1\\) loss and the Adam optimizer (default option in the learner).\n\nlearn = Learner(dls, model, loss_func=L1LossFlat(), model_dir=MODEL_PATH)\n\nA rather handy functionality of the learner is the lr_find method. This function trains the model for a few mini-batches changing the learning rate. Then, we can visualize the loss and determine the regions where the model is learning, where the learning rate is too low and where it diverges.\n\nlearn.lr_find()\n\n\n\n\nSuggestedLRs(lr_min=0.0005248074419796466, lr_steep=1.3182567499825382e-06)\n\n\n\n\n\nThis is a typical shape where we have a regime where the model is not learning, followed by a fast-learning regime (slope downhill) and then a divergence region. We usually take a learning rate that is about 10x below the valley.\nThen we train with fit_one_cycle, which follows the one-cycle policy. We typically train with a few epochs and, if we see the model is still learning and not overfitting, we resume the training.\n\nlearn.fit_one_cycle(30, lr_max=2e-4)\n\nFinally, we can save the model.\n\nlearn.save(f'xresattn_bm_{dim}d_1_to_4_cp')"
  },
  {
    "objectID": "tutorials/model_training.html#generate-the-data-1",
    "href": "tutorials/model_training.html#generate-the-data-1",
    "title": "Model training",
    "section": "Generate the data",
    "text": "Generate the data\nWe generate the data in a very similar way as in the Brownian motion case. We combine data sets with anomalous diffusion trajectories that have different numbers of segments. Since there are two variables: \\(\\alpha\\) and anomalous diffusion model, we consider a new segment whenever, at least one, of the two quantities varies.\n\n\n\n\n\n\nNote\n\n\n\nSkip this section if you already have a data set to train!\n\n\nIn this training data set, we will consider all the diffusion models with all their available exponents. Furthermore, we will not add any localization noise to the raw data, as we will use our LocalizationNoise data augmentation during training.\n\nn_per_set = 12500\nmax_t = 200\ndim = 2 \ncps = [1, 2, 3, 4]\nds_fun = partial(create_andi_segmentation_dataset,\n                 max_t=max_t, dim=dim, noise=[0.], save=False)\n\n\ndatasets = [ds_fun(n_per_set, n_change_points=n_cp) for n_cp in cps]\ndataset = combine_datasets(datasets)\n\nn_change = f\"{min(cps)}_to_{max(cps)}\"\nsave_path = DATA_PATH/get_andids_fname(n_change, max_t, dim, \"train\")\ndataset.to_pickle(save_path)\n\n\n\n\n\n\n\nNote\n\n\n\nYou may see some warnings while the data set is createad, but don’t panic, they’re harmless."
  },
  {
    "objectID": "tutorials/model_training.html#train-the-models",
    "href": "tutorials/model_training.html#train-the-models",
    "title": "Model training",
    "section": "Train the models",
    "text": "Train the models\nWe will show two examples: a regression task for the anomalous diffusion exponent and a classification task for the anomalous diffusion model. The whole pipeline is very similar to the case of Brownian motion: load data loaders, model and cost function in a learner and train.\n\nAnomalous diffusion exponent\nThe task here is to predict \\(\\alpha\\). Thus, we will set target=y_exp in the data loader.\n\ndim = 2\ndls = get_segmentation_dls(dim=dim, target='y_exp',\n                           n_change='1_to_4', name='train')\ndls.device = default_device()\n\nIn this case, we add localization noise with \\(\\sigma_{\\text{noise}}\\in\\left[10^{-4}, 10^0\\right]\\) and we leave some noiseless trajectories.\n\nnoise_levels = torch.cat([-tensor([float('inf')]),\n                          torch.linspace(-4, 0, 11)])\ndls.add_tfms(LocalizationNoise(noise_levels), 'after_item')\n\nThen, we can create our model and combine all together in a Learner.\n\nmodel = XResAttn(dim, n_class=1, stem_szs=(32,), conv_blocks=[1, 1, 1],\n                 block_szs=[128, 256, 512], pos_enc=False, n_encoder_layers=4,\n                 dim_ff=512, nhead_enc=8, linear_layers=[])\nmodel.to(default_device())\nlearn_exp = Learner(dls, model, loss_func=L1LossFlat(), model_dir=MODEL_PATH)\n\nJust as before, we can look for a suitable learning rate and train the model.\n\nlearn_exp.lr_find()\n\n\nlearn_exp.fit_one_cycle(20, lr_max=2e-4)\n\nFinally, we can save the trained model.\n\nlearn_exp.save(f'xresattn_exp_{dim}d_1_to_4_cp')\n\n\n\nAnomalous diffusion model\nTo know what is the anomalous diffusion model that best describes the observations, we need to perform a pointwise classification task. We have 5 possible classes corresponding to each of the models.\n\n\n\n\n\n\nNote\n\n\n\nIn our paper, we do not show any example of this task.\n\n\nIn this case, we do not need to set target=y_mod, as it is the default option for our data loaders.\n\ndim = 2\ndls = get_segmentation_dls(dim=dim, n_change='1_to_4', name='train')\ndls.device = default_device()\nnoise_levels = torch.cat([-tensor([float('inf')]),\n                          torch.linspace(-4, 0, 11)])\ndls.add_tfms(LocalizationNoise(noise_levels), 'after_item')\n\nCreating our model, we do not need to specify n_class=5 because it’s the default option.\n\nmodel = XResAttn(dim, stem_szs=(32,), conv_blocks=[1, 1, 1],\n                 block_szs=[128, 256, 512], pos_enc=False, \n                 n_encoder_layers=4, dim_ff=512, nhead_enc=8,\n                 p=0.5, dropout=0.6, linear_layers=[])\nmodel.to(default_device())\n\nIn the previous cases, the loss function was a direct indicative of the metric that we cared about. However, in this case, it is convenient to track additional metrics, such as the F1 score.\nAs loss function, we use the cross entropy loss with label smoothing, a very sucessful regularization technique.\n\nmetrics = [F1Score(average='micro')]\nlearn = Learner(dls, model, loss_func=LabelSmoothingCrossEntropyFlat(),\n                metrics=metrics, model_dir=MODEL_PATH)\n\nJust as before, we can look for a suitable learning rate.\n\nlearn.lr_find()\n\nTrain our model.\n\nlearn.fit_one_cycle(20, lr_max=2e-3)\n\nAnd save it!\n\nlearn.save(f'xresattn_class_{dim}d_1_to_4cp')"
  },
  {
    "objectID": "tutorials/index_tutorials.html",
    "href": "tutorials/index_tutorials.html",
    "title": "Tutorials",
    "section": "",
    "text": "With these tutorials, we aim to make our library more accessible to everyone. Our goal is to show how to reproduce the results of our paper and provide you with the necessary tools to tackle your problems following our approach.\nThe tutorials include:\n\nModel training: an introduction to generate data sets and train machine learning models to characterize heterogeneous diffusive processes.\nBenchmark: Brownian motion: a characterization of the capabilities of our approach to study Brownian motion with changes over time.\nBenchmark: anomalous diffusion: a characterization of the capabilities of our approach to study anomalous diffusion processes with changes over time.\nAnomalous diffusion from normal diffusion: examples of how to use the time-dependent normal diffusion properties through time to understand the emergence of anomalous diffusion."
  },
  {
    "objectID": "tutorials/analysis_bm.html",
    "href": "tutorials/analysis_bm.html",
    "title": "Benchmark: Brownian motion",
    "section": "",
    "text": "The main goal is to characterize heterogeneous diffusion processes without any kind of prior konwledge. To do so, we predict the diffusion coefficient at every time step, which naturally highlights potential changes in the behaviour along the trajectories. This allows us to obtain a deeper understanding of the underlying physical systems that drive the dynamics.\nIn the following analysis, we provide a thorough characterization of the model performance under various conditions and we show how to reproduce some figures of our paper."
  },
  {
    "objectID": "tutorials/analysis_bm.html#generate-the-data",
    "href": "tutorials/analysis_bm.html#generate-the-data",
    "title": "Benchmark: Brownian motion",
    "section": "Generate the data",
    "text": "Generate the data\nTo evaluate the different methods, we need a proper test set. We can generate one in the same way that we genereate the train set in the model training tutorial.\n\n\n\n\n\n\nNote\n\n\n\nSkip the data generation if you already have a test set!\n\n\n\n# OPTIONAL: create the test set.\n# Don't need to run this cell if it already exists.\nn_per_set, max_t, dim = 12000, 200, 2\nDs = np.logspace(-3, 3, 1000) \ncps = [1, 2, 3, 4]\nds_fun = partial(create_bm_segmentation_dataset,\n                 max_t=max_t, dim=dim, Ds=Ds, save=False)\ndatasets = [ds_fun(n_per_set, n_change_points=n_cp) for n_cp in cps]\nds = combine_datasets(datasets)\nn_change = f\"{min(cps)}_to_{max(cps)}\"\nsave_path = DATA_PATH/get_bmds_fname(n_change, max_t, dim, 'test')\nds.to_pickle(save_path)\n\nLoad the test set.\n\n# Skip this cell if you just generated it.\nn_change = \"1_to_4\"\nname = \"test\"\nds = load_dataset(n_change=n_change, dim=dim, bm=True, name=name)\n\nWe also load the data as data loaders with split_pct=1 (all data for validation). This allows us to loop over batches much more easily setting shuffle=False.\n\nbs = 200\ndls = get_segmentation_dls(target='y_exp', dim=dim, n_change=n_change,\n                           name=name, tfm_y=torch.log10, bm=True, bs=bs,\n                           shuffle=False, split_pct=1.)\ndls.device = default_device()"
  },
  {
    "objectID": "tutorials/analysis_bm.html#get-the-predictions",
    "href": "tutorials/analysis_bm.html#get-the-predictions",
    "title": "Benchmark: Brownian motion",
    "section": "Get the predictions",
    "text": "Get the predictions\nWe now perform the predictions of the trajectories as a whole and store them in the dataframe to process them later.\n\nfor i, (x, y) in tqdm(enumerate(dls.valid)):\n    pred = to_detach(learn_diff.model(x).squeeze())\n    mae = to_detach((learn_diff.model(x).squeeze()-y).abs().mean(-1))\n    l_pred = np.array([p for p in pred], dtype=object)\n    ds.loc[i*bs:(i+1)*bs-1, 'mae'] = mae.numpy()\n    ds.loc[i*bs:(i+1)*bs-1, 'pred'] = l_pred\n\n\n\n\nWith the full-trajectory predictions, we can proceed to perform the segment-wise analysis. We split the trajectories and their predictions by the true changepoints. Then, we perform the prediction especifically for each segment with both the model and the TA-MSD method. We choose the TA-MSD 1-2 to perform the evaluation, which is optimal for Brownian motion.\nLet’s define a prediction function to simplify the code.\n\ndef predict_sample(model, x):\n    xb = x.unsqueeze(0).to(default_device())\n    return to_detach(model(xb).squeeze())\n\nNow we can proceed to process the trajectories. The following piece of code is rather chonky so let us give a brief overview. For every trajectory (outer loop), we process each of its segments (inner loop). For every segment, we compute the mean absolute error (MAE) and the mean relative error with the three aforementioned approaches.\n\nsegment_data = []\n\nfor i, row in tqdm(ds.iterrows()):\n    x, y,= row.x, torch.log10(row.y_exp.squeeze())\n    pred, cps = row.pred, row.cp\n    split_x = split_tensor(x.T, cps)\n    split_y, split_pred = split_tensor(y, cps), split_tensor(pred, cps)\n    \n    splits = zip(split_x, split_y, split_pred)\n    for j, (seg_x, seg_y, pred_cut) in enumerate(splits):\n        # Prediction over full trajectory cut with true changepoints\n        mae = mean_absolute_error(pred_cut, seg_y)\n        rel_err = mean_relative_error(pred_cut, seg_y)\n        \n        # Prediction over segment\n        pred_segment = predict_sample(learn_diff.model, seg_x - seg_x[0])\n        mae_segment = mean_absolute_error(pred_segment, seg_y)\n        rel_err_segment = mean_relative_error(pred_segment, seg_y)\n        \n        # Prediction over segment with TA-MSD\n        pred_tamsd = diffusion_coefficient_tamsd(seg_x)\n        mae_tamsd = mean_absolute_error(pred_tamsd, 10**seg_y[0])\n        rel_err_tamsd = (pred_tamsd*10**(-seg_y[0]) - 1).abs()\n        \n        # Save the segment metrics\n        segment_data.append({'sample': i, 'segment_idx': j,\n                             'length': len(seg_y), 'x': seg_x, 'y': seg_y,\n                             'pred_cut': pred_cut,\n                             'pred_segment': pred_segment,\n                             'pred_tamsd': pred_tamsd, 'mae': mae,\n                             'rel_err': rel_err, 'mae_segment': mae_segment,\n                             'rel_err_segment': rel_err_segment,\n                             'mae_tamsd': mae_tamsd,\n                             'rel_err_tamsd': rel_err_tamsd})\nsegment_ds = pd.DataFrame.from_records(segment_data)\n\n\n\n\nFinally, we save all the data for its posterior post-processing. It is extremely heavy and slow :D\n\nsegment_ds.to_pickle(DATA_PATH/\"segment_analysis_test.pkl\")"
  },
  {
    "objectID": "tutorials/analysis_bm.html#overall-performance",
    "href": "tutorials/analysis_bm.html#overall-performance",
    "title": "Benchmark: Brownian motion",
    "section": "Overall performance",
    "text": "Overall performance\nTo obtain an intuition of our model’s performance, we can do a qualitative analysis by looking at the predicted diffusion coefficient \\(D_{\\text{pred}}\\) as function of the ground truth \\(D_{\\text{true}}\\) at every time step.\nTo do so, we simply concatenate the predictions for every segment segment_ds.pred_cut and their true labels segment_ds.y.\n\ntrue = np.concatenate([*segment_ds.y])\npred = np.concatenate([*segment_ds.pred_cut])\n\nNow we can build the 2D histogram.\n\nbins = [np.linspace(-3, 3, 61), np.linspace(-3.1, 3.1, 63)]\nhist, true_edges, pred_edges = np.histogram2d(true, pred, bins=bins)\n\n\n\nCode\nfig = plt.figure(figsize=(1.1*fig_size, fig_size))\nplt.pcolor(hist.transpose()/hist.max(), cmap=cmap_hist1, vmax=0.8, rasterized=True)\nxtick_pos = np.linspace(0, len(true_edges) - 1, np.ceil(len(true_edges)/30).astype(int))\nxtick_labels = [fr'$10^{{{i:.0f}}}$' for i in true_edges[::30]]\nytick_pos = np.linspace(0, len(pred_edges) - 3, np.ceil(len(pred_edges)/30).astype(int)) + 1\nytick_labels = [fr'$10^{{{i:.0f}}}$' for i in pred_edges[1::30]]\nplt.yticks(ytick_pos, labels=ytick_labels)\nplt.ylabel(r'$D_{pred}$', fontsize=16)\nplt.xticks(xtick_pos, xtick_labels)\nplt.xlabel(r'$D_{true}$', fontsize=16)\nplt.tick_params(labelsize=14)\n\n\n\n\n\nThe histogram shape is close to a perfect regressor, where we would obtain a straight diagonal line. Therefore, the model seems to be working pretty nicely!"
  },
  {
    "objectID": "tutorials/analysis_bm.html#prediction-error",
    "href": "tutorials/analysis_bm.html#prediction-error",
    "title": "Benchmark: Brownian motion",
    "section": "Prediction error",
    "text": "Prediction error\nTo obtain a quantitative analysis, we can look at the relative error of the different methods.\n\nlengths = segment_ds.length.unique().astype(int)\nlengths.sort()\n\nmetrics = ['err', 'err_segment', 'err_tamsd']\nmetric_by_length = {m: {'mean': [], 'sem': [], 'global': None}\n                    for m in metrics}\n\nfor m in metrics:\n    means = [getattr(segment_ds, f\"rel_{m}\")[segment_ds.length == l].mean()\n             for l in lengths]\n    sems = [getattr(segment_ds, f\"rel_{m}\")[segment_ds.length == l].sem()\n            for l in lengths]\n        \n    metric_by_length[m]['mean'] = np.array(means)\n    metric_by_length[m]['sem'] = np.array(sems)\n    metric_by_length[m]['global'] = (\n        (getattr(segment_ds, f\"rel_{m}\")*segment_ds.length).sum() /\n         segment_ds.length.sum()\n    )\n\nWe save all these metrics to plot them nicely later.\n\nfigure_name = \"relative_error_segment_length\"\nplot_data_path = (FIG_PATH/figure_name).with_suffix(\".pkl\")\n\nwith open(plot_data_path, 'wb') as f:\n    pickle.dump(metric_by_length, f, protocol=pickle.HIGHEST_PROTOCOL)\n\nLet’s see the overall relative error for each method.\n\n\nCode\nprint(f\"STEP: {metric_by_length_D['err']['global']:.3f}\")\nprint(f\"STEP + segments: {metric_by_length_D['err_segment']['global']:.3f}\")\nprint(f\"TA-MSD + segments: {metric_by_length_D['err_tamsd']['global']:.3f}\")\n\n\nSTEP: 0.226\nSTEP + segments: 0.189\nTA-MSD + segments: 0.249\n\n\nSTEP outperforms the TA-MSD baseline despite its disadvantage. It even reduces the error by \\(\\sim 25\\%\\) when we consider the pre-segmented trajectory! In the plot right below, we see the prediction error over segments at different lengths.\n\n\nCode\nfig = plt.figure(figsize=(1.5*fig_size, fig_size))\nlabels = ['STEP', 'STEP + segments', 'TA-MSD + segments']\nmarkers = ['o', 's', 'D']\n\nfor i, m in enumerate(metric_by_length.keys()):\n    mean, sem = metric_by_length[m]['mean'], metric_by_length[m]['sem']\n    plt.plot(lengths, mean, color=colors[i], label=labels[i],\n             zorder=-i, lw=linewidth)\n    plt.fill_between(lengths, mean - sem, mean + sem, color=colors[i],\n                     alpha=0.3, zorder=-i)\n\nplt.grid(alpha=alpha_grid)\nplt.legend(fontsize=11)\nplt.tick_params(labelsize=14)\nplt.ylim([0.05, 0.75])\nplt.xticks([10, 50, 100, 150, 190])\nplt.yticks([0.2, 0.4, 0.6])\nplt.xlabel(\"Segment length\", fontsize=16)\nplt.ylabel(\"Relative error\", fontsize=16);\n\n\n\n\n\nSTEP systematically outperforms the TA-MSD baseline for short segments. Furthermore, when we provide it with the isolated segments, we can achieve outstanding low errors, specially for the shortest segments. This is reasonable because the shorter segments carry much less information to properly determine \\(D\\), and they can even be confused with simple stochastic fluctuations of the phenomena. This makes it harder to accurately determine the segment boundaries, as shown by the difference between the blue and red lines."
  },
  {
    "objectID": "tutorials/analysis_bm.html#generate-the-data-1",
    "href": "tutorials/analysis_bm.html#generate-the-data-1",
    "title": "Benchmark: Brownian motion",
    "section": "Generate the data",
    "text": "Generate the data\nIn order to obtain a better insight about the strengths of the methods, we test them in trajectories with one single changepoint. In this way, we study how the changepoint position and difference between diffusion coefficient in consecutive segments affects the performance.\n\nDs = np.logspace(-3, 3, 1000) \nds = create_bm_segmentation_dataset(50000, dim=dim, Ds=Ds)\n\n\nds['y'] = ds['y_exp'].apply(torch.squeeze)\nds['y_log'] = ds['y'].apply(torch.log10)\nds['D_diff'] = ds['y_log'].apply(lambda x: (x[1] - x[0]).item())\nds['cp'] = ds['cp'].apply(lambda x: x.numpy())\nds = ds.drop(columns=['y_mod', 'y_exp', 'models', 'exps'])"
  },
  {
    "objectID": "tutorials/analysis_bm.html#get-the-predictions-1",
    "href": "tutorials/analysis_bm.html#get-the-predictions-1",
    "title": "Benchmark: Brownian motion",
    "section": "Get the predictions",
    "text": "Get the predictions\nLet’s get the predictions! We define a couple of functions to make our code more readable.\n\ndef make_batch(df, i, bs, col='x'):\n    \"Return a batch of samples from df.\"\n    samples = [x.transpose(-1, 0) for x in ds.loc[i*bs:(i+1)*bs-1, col]]\n    return torch.stack(samples, dim=0)\n\ndef predict(model, x):\n    \"Get prediction of `model` on batch `x`.\"\n    return to_detach(model(x.to(default_device())).squeeze()\n\nReady to go!\n\nbs = 400\nn_batch = np.ceil(ds.shape[0]/bs).astype(int)\nfor i in tqdm(range(n_batch)):\n    xb = make_batch(ds, i, bs)\n    pred = predict(learn_diff.model, xb)\n    ds.loc[i*bs:(i+1)*bs-1, 'pred'] = np.array([p for p in pred],\n                                               dtype=object)\n\n\n\n\nLet’s save this for later.\n\nds_path = DATA_PATH/get_bmds_fname(1, max_t, dim, 'with_preds')\nds.to_pickle(ds_path)"
  },
  {
    "objectID": "tutorials/analysis_bm.html#overall-performance-1",
    "href": "tutorials/analysis_bm.html#overall-performance-1",
    "title": "Benchmark: Brownian motion",
    "section": "Overall performance",
    "text": "Overall performance\nLet’s compute the JI for the task using the STEP predictions and the trajectory displacements for the kernel changepoint prediction algorithm in ruptures.\nTo ease the code readability, we define a function to combine two dictionaries together (adhoc for our purposes).\n\ndef merge_dict(dict_1, dict_2):\n    \"Merge the information of two dictionaries.\"\n    merge = {}\n    for k, v1 in dict_1.items():\n        v2 = dict_2.get(k, [])\n        if isinstance(v1, Iterable) and isinstance(v2, Iterable):\n            merge[k] = [*v1, *v2]\n        elif isinstance(v1, Iterable):\n            merge[k] = [*v1, v2]\n        elif isinstance(v2, Iterable):\n            merge[k] = [v1, *v2]\n        else:\n            merge[k] = [v1, v2]\n    return merge\n\nNow we process every trajectory and retrieve the changepoints with ruptures using both the displacements and the STEP prediction. Then, we compute the JI between the prediction and the ground truth and, finally, the MSE for the true positives.\n\nmethod_pen = {'pred': 2., 'displ': 6.}\nmethods = list(method_pen.keys())\n\nmetrics_method = {m: {} for m in methods}\nfor i, row in tqdm(ds.iterrows()):\n    traj, pred, true_cp = row.x.numpy(), row.pred.numpy(), row.cp\n    displacements = np.log(get_displacements(traj))\n\n    for m in methods:\n        seg_data = (pred if m == 'pred'\n                    else displacements if m == 'displ'\n                    else None)\n        pred_cp = ruptures_cp(seg_data, pen=method_pen[m], min_size=5)\n        metrics = evaluate_cp_prediction(true_cp, pred_cp)\n        metrics_method[m] = merge_dict(metrics, metrics_method[m])\n        for k, v in metrics.items():\n            if metrics['tp']:\n                ds.loc[i, f'cp_{m}_{k}'] = v[0] if k == 'sq_error' else v\n            else:\n                ds.loc[i, f'cp_{m}_{k}'] = -1 if k == 'sq_error' else v\n\nNow we can compute the overall JI and MSE for both approaches over the whole test set.\n\nmethod_mse, method_j_idx = {}, {}\nfor m, v in metrics_method.items():\n    method_mse[m] = np.mean(v['sq_error'])\n    tp, fp, fn = np.sum(v['tp']), np.sum(v['fp']), np.sum(v['fn'])\n    method_j_idx[m] = jaccard_index(tp, fp, fn)\n\n\n\n\n\nmethod_j_idx, method_mse\n\n({'pred': 0.8333494778851929, 'displ': 0.7963921392139214},\n {'pred': 0.6803905614320586, 'displ': 0.6163644925829997})\n\n\nWe see that running rutpures on top of STEP increases the JI from 0.796 to 0.833, meaning that we reduce the errors by about \\(20\\%\\). It is natural to expect that, by detecting more changepoints (higher JI), the method then incurs a larger MSE. This is because we consider a threshold of \\(\\mathcal{E}=5\\) points from the ground truth to count the predictions as true positive. The results indicate that the additional changepoints detected with STEP lie, most likely, at the limit of the threshold."
  },
  {
    "objectID": "tutorials/analysis_bm.html#difference-between-consecutive-segments",
    "href": "tutorials/analysis_bm.html#difference-between-consecutive-segments",
    "title": "Benchmark: Brownian motion",
    "section": "Difference between consecutive segments",
    "text": "Difference between consecutive segments\nNow that we have an idea of the overall behaviour of both methods, let’s look at the JI as function of the relative difference between \\(D\\) of consecutive segments. Inuitively, the larger the difference, the easier it is to detect where the change is happening.\n\n\n\n\n\n\nNote\n\n\n\nBeware that the difference in log space is the ratio in real space. Don’t get confused :)\n\n\n\nbins_D_diff = np.linspace(-6, 6, 100) # Difference in log space\nj_idx_by_diff = {m: [] for m in methods}\nmse_by_diff = {m: [] for m in methods}\n\nfor low, high in zip(bins_D_diff[:-1], bins_D_diff[1:]):\n    mask = (ds.D_diff &gt;= low) & (ds.D_diff &lt; high)\n    for m in methods:\n        tp = ds.loc[mask, f'cp_{m}_tp'].sum()\n        fp = ds.loc[mask, f'cp_{m}_fp'].sum()\n        fn = ds.loc[mask, f'cp_{m}_fn'].sum()\n        j_idx_by_diff[m].append(jaccard_index(tp, fp, fn))\n        \n        mask_mse = mask & (ds.loc[:, f'cp_{m}_tp'] == 1)\n        mse_by_diff[m].append(ds.loc[mask_mse, f'cp_{m}_sq_error'].mean())\n\n\n\nCode\nmethod_color = {'pred': colors[0], 'displ': colors_light[3]}\nmethod_label = {'pred': 'KCPD + STEP', 'displ': 'KCPD + displ'}\nmethod_ls = {'pred': 'solid', 'displ': 'dashed'}\n\nfig = plt.figure(figsize=(1.5*fig_size, fig_size))\nplt_x = bins_D_diff[:-1] + np.diff(bins_D_diff)\nfor m in methods:\n    plt.plot(plt_x, j_idx_by_diff[m], linewidth=linewidth, label=method_label[m],\n              color=method_color[m], linestyle=method_ls[m])\nplt.grid(alpha=alpha_grid)\nplt.ylim([-0.05, 1.05])\nplt.yticks([0., 0.5, 1.])\nplt.xticks(np.arange(-6, 7, 2), [f\"$10^{{{t}}}$\" for t in np.arange(-6, 7, 2)])\nplt.legend(fontsize=14)\nplt.xlabel(r\"$D_2/D_1$\", fontsize=16)\nplt.ylabel(\"Jaccard index\", fontsize=16)\nplt.tick_params(labelsize=14)\n\n\n\n\n\nWe see that the changepoint method with STEP does, indeed, outperform the baseline for the whole range of \\(D_2/D_1\\). They converge to the same results in the limit of very similar diffusion coefficients \\(D_2\\approx D_1\\), where the changes is barely detectable. Indeed, when \\(D_2=D_1\\) there is no change to detect!\nInterestingly, we get a nearly perfect detection when the diffusion coefficients are just one order of magnitude appart."
  },
  {
    "objectID": "tutorials/analysis_bm.html#changepoint-position",
    "href": "tutorials/analysis_bm.html#changepoint-position",
    "title": "Benchmark: Brownian motion",
    "section": "Changepoint position",
    "text": "Changepoint position\nWe can also study the impact of the changepoint position in the detection, which was shown to be a very important factor in the AnDi Challenge. Shorter segments are much harder to characterize and, by the same principle we saw the error increase for short segments, we expect the performance to drop when the change point is near the trajectory ends.\n\nbins_cp_pos = np.arange(10, 200, 10)\nj_idx_by_position_D = {m: [] for m in methods}\nfor low, high in zip(bins_cp_pos[:-1], bins_cp_pos[1:]):\n    mask = (low &lt;= ds.cp) & (ds.cp &lt; high)\n    for m in methods:\n        tp = ds.loc[mask, f'cp_{m}_tp'].sum()\n        fp = ds.loc[mask, f'cp_{m}_fp'].sum()\n        fn = ds.loc[mask, f'cp_{m}_fn'].sum()\n        j_idx_by_position_D[m].append(jaccard_index(tp, fp, fn))\n\n\n\nCode\nfig = plt.figure(figsize=(1.5*fig_size, fig_size))\nfor m in methods:\n    plt.plot(j_idx_by_position_D[m], linewidth=linewidth, label=method_label[m],\n              color=method_color[m], linestyle=method_ls[m])\nx_tick_idx = np.array([0, 9, 17])\nplt.xticks(x_tick_idx, \n           [f'{low}-{high}' for low, high in zip(bins_cp_pos[x_tick_idx], bins_cp_pos[x_tick_idx+1])])\nplt.grid(alpha=alpha_grid)\nplt.ylim([-0.05, 1.05])\nplt.yticks([0., 0.5, 1.])\nplt.ylabel(\"Jaccard index\", fontsize=16)\nplt.xlabel(\"Changepoint position\", fontsize=16)\nplt.tick_params(labelsize=14)\n\n\n\n\n\nAgain, we clearly see how STEP outperforms the baseline with trajectory displacements in all circumstances. Furthermore, both methods show impressive resilience to the changepoint position, as their performance is barely affected by it."
  },
  {
    "objectID": "tutorials/analysis_bm.html#generate-the-data-2",
    "href": "tutorials/analysis_bm.html#generate-the-data-2",
    "title": "Benchmark: Brownian motion",
    "section": "Generate the data",
    "text": "Generate the data\nWe generate a data set comprised of trajectories with different number of segments at several constant segment lengths. This way, we can look at the impact of both the number of segments and their lengths separately.\nWe define our custom methods here just for this test, provided that we do not have adhoc functions to generate this kind of data. You can skip these cells if you already have a test set.\n\n@delegates(brownian_motion)\ndef constant_segment_trajs(N, segment_length, n_change_points=1,\n                                  Ds=np.logspace(-3, 3, 1000), **kwargs):\n    \"Create `N` trajectories with constant segment length.\"\n    n_segments = n_change_points + 1\n    max_t = n_segments * segment_length\n    segment_D = np.random.choice(Ds, size=(N, n_segments))\n    point_D = np.repeat(segment_D, segment_length, axis=-1)[:, None, :]\n    bms = brownian_motion(N, max_t, point_D, **kwargs)\n    return bms, point_D\n\ndef create_constant_segment_dataset(N, segment_length,\n                                    n_change_points=1, dim=2):\n    \"Creates a dataset of `N` trajectories with constant segment length.\"\n    data = []\n    trajs, labels = constant_segment_trajs(N, segment_length, \n                                           n_change_points=n_change_points,\n                                           dim=dim)\n    length = trajs.shape[-1]\n    cp = np.arange(segment_length, length, segment_length)\n    for traj, label in zip(trajs, labels):\n        x, y = tensor(traj), tensor(label).squeeze()\n        data.append({'dim': dim, 'len': length, 'seg_len': segment_length,\n                        'n_cp': n_change_points, 'cp': cp,\n                        'x': x, 'y': y, 'y_log': torch.log10(y)})\n    return pd.DataFrame.from_records(data)\n\nWith these functions, we can easily create our data set. We consider trajectories with none to 10 changepoints and segment lengths of 20, 40 and 60.\n\nn_set, segment_lengths, cps = 2000, [20, 40, 60], np.arange(11)\nDs = np.logspace(-3, 3, 1000) \ndatasets = [create_constant_segment_dataset(n_set, sl, n_change_points=n_cp) \n            for sl in segment_lengths for n_cp in tqdm(cps)]\nds = combine_datasets(datasets, shuffle=False)"
  },
  {
    "objectID": "tutorials/analysis_bm.html#get-the-predictions-2",
    "href": "tutorials/analysis_bm.html#get-the-predictions-2",
    "title": "Benchmark: Brownian motion",
    "section": "Get the predictions",
    "text": "Get the predictions\nWith our dataset ready, we can proceed to perform the predictions. We store them in the same dataframe.\n\nbs = 50\nn_batch = np.ceil(ds.shape[0]/bs).astype(int)\nfor i in tqdm(range(n_batch)):\n    xb = make_batch(ds, i, bs).to(default_device())\n    pred = to_detach(learn_diff.model(xb)).squeeze()\n    ds.loc[i*bs:(i+1)*bs-1, 'pred'] = np.array([p for p in pred], dtype=object)"
  },
  {
    "objectID": "tutorials/analysis_bm.html#pointwise-error",
    "href": "tutorials/analysis_bm.html#pointwise-error",
    "title": "Benchmark: Brownian motion",
    "section": "Pointwise error",
    "text": "Pointwise error\nSo far, we have characterized the prediction error with various metrics, such as the mean absolute error or the relative error, which focus on the pointwise performance.\nHowever, the pointwise relative error is a rather volatile quantity. For instance, in the case there is a large change between consecutive diffusion coefficients, e.g., from \\(10^3\\) to \\(10^{-3}\\), even if the agent performs a perfect characterization, but fails by a single point, the relative error for the whole trajectory shoots up to \\(\\sim10^6\\). Therefore, in order to obtain a better understanding of the actual prediction error, \\(D_{\\text{true}} - D_{\\text{pred}}\\), we consider the mean prediction of each segment \\(D_{\\text{true}} - \\langle D_{\\text{pred}}\\rangle_{\\text{seg}}\\).\n\ndef segment_rel_error(pred, y, cp):\n    \"Segment-wise relative error. Assumes `pred` and `y` in log10.\"\n    segment_preds = split_tensor(pred, cp)\n    segment_means = torch.stack([p.mean() for p in segment_preds])\n    true_values = torch.cat([y[0].unsqueeze(0), y[cp]])\n    return (10**(segment_means - true_values) - 1).abs().mean()\n\n\n# metrics\nds['mae'] = (ds['pred'] - ds['y_log']).abs().apply(torch.mean)\nds['seg_rel_error'] = ds.apply(lambda x: segment_rel_error(x['pred'],\n                                                           x['y_log'], x['cp']),\n                                                           axis=1)\n\nSave the data for posterior processing.\n\nds_path = DATA_PATH/\"constant_segment_analysis.pkl\"\nds.to_pickle(ds_path)\n\nFinally, we compute the value of the relative erorr as a function of the number of change points.\n\ndef get_metric_sem_per_cp(metric, ds):\n    \"Returns the metric per change point from dataset ds.\"\n    segment_lengths = ds.seg_len.unique().astype(int)\n    n_cps = ds.n_cp.unique().astype(int)\n    metric_per_cp = np.zeros((len(segment_lengths), len(n_cps)))\n    err_per_cp = np.zeros_like(metric_per_cp)                         \n    for k, length in enumerate(segment_lengths):\n        mask = (ds.seg_len == length) & (ds.n_cp == n_cp)\n        metric_per_cp[k, :] = np.array([getattr(ds, metric)[mask].mean()\n                                        for n_cp in n_cps])\n        err_per_cp[k, :] = np.array([getattr(ds, metric)[mask].sem()\n                                     for n_cp in n_cps])\n    return metric_per_cp, err_per_cp\n\n\nmetric = 'seg_rel_error'\nrel_err_per_cp, rel_err_sem_per_cp = get_metric_sem_per_cp(metric, ds)\n\n\n\nCode\nmarkers = ['o', 's', 'D']\nshades_blue = [colors_light[0], colors[0], colors_dark[0]]\nn_seg_rel_error = ds.n_cp.unique().astype(int) + 1\n\nfig = plt.figure(figsize=(1.5*fig_size, fig_size))\nfor k, (val, err, length) in enumerate(zip(rel_err_per_cp, rel_err_sem_per_cp, segment_lengths)):\n    plt.plot(n_seg_rel_error, val, marker = markers[k], label=f\"length {length}\", c=shades_blue[k],\n               markerfacecolor='w', lw=linewidth)\n    plt.fill_between(n_seg_rel_error, val - err, val + err, alpha=0.3, color=colors[0])\nplt.xticks([2, 6, 10])\nplt.ylim([0.16, 0.39])\nplt.legend(fontsize=14, loc='upper left')\nplt.xlabel(\"Number of segments\", fontsize=16)\nplt.ylabel(\"Relative error\", fontsize=16)\nplt.grid(alpha=alpha_grid)\nplt.tick_params(labelsize=14)\n\n\n\n\n\nWe see that the error increases linearly with the number of segments. This means that every additional segment adds the same source of errors despite of how many there may already be.\nFurthermore, we see that the segment length has a much larger impact than the number of segments. For instance, it is harder to characterize a trajectory with two segments of length 20 (40 time steps in total), than one with 11 segments of length 40 (440 time steps in total). However, in concordance with the first results in this tutorial, once we reach a certain minimum length, the error stabilizes."
  },
  {
    "objectID": "tutorials/analysis_bm.html#changepoint-detection-1",
    "href": "tutorials/analysis_bm.html#changepoint-detection-1",
    "title": "Benchmark: Brownian motion",
    "section": "Changepoint detection",
    "text": "Changepoint detection\nLet’s see now the impact on the changepoint detection task. We will compute the JI as a function of the number of segments.\nFirst of all, we filter out those trajectories without any changepoint.\n\nds_cp = ds[ds.n_cp != 0].reset_index(drop=True)\n\nNow let’s calculate the true positives, false positives and false negatives of every prediction to obtain the JI (see above and our model evaluation methods).\n\nj_idx_parameters = {'tp': [], 'fp': [], 'fn': []}\nfor _, (pred, cp) in ds_cp[['pred', 'cp']].iterrows():\n    metrics = evaluate_cp_prediction(cp, ruptures_cp(pred.numpy(), pen=2.))\n    for k, v in metrics.items():\n        if k in j_idx_parameters.keys():\n            j_idx_parameters[k].append(v)\n\nfor k, v in j_idx_parameters.items():\n    ds_cp[k] = v\n\nFinally, we can compute the JI as function of the number of changepoints for every segment length.\n\nj_idx_per_cp = np.zeros_like(rel_err_per_cp)[:, :-1]\nfor i, length in enumerate(ds_cp.seg_len.unique()):\n    for j, n_cp in enumerate(ds_cp.n_cp.unique().astype(int)):\n        mask = (ds_cp.seg_len == length) & (ds_cp.n_cp == n_cp)\n        j_idx_per_cp[i, j] = jaccard_index(ds_cp.tp[mask].sum(),\n                                           ds_cp.fp[mask].sum(),\n                                           ds_cp.fn[mask].sum())\n\n\n\nCode\nn_seg = ds_cp.n_cp.unique().astype(int) + 1\nfor k, (val, length) in enumerate(zip(j_idx_per_cp, segment_lengths)):\n    plt.plot(n_seg, val, marker = markers[k], label=f\"Length {length}\", c=shades_blue[k],\n               markerfacecolor='w', lw=linewidth)\n    # ax[1].fill_between(n_seg, val - err, val + err, alpha=0.3, color=colors[0])\nxticks = [2, 6, 10]\nplt.xticks(xticks)\nplt.ylim([0.7, 1.])\nplt.yticks([0.7, 0.8, 0.9, 1.])\nplt.grid(alpha=alpha_grid)\nplt.legend(fontsize=14)\nplt.ylabel(\"Jaccard Index\", fontsize=16)\nplt.xlabel(\"Number of segments\", fontsize=16)\nplt.tick_params(labelsize=14)\n\n\n\n\n\nAgain, we see that shorter segments are harder to characterize, and that segment length does not play a significant role beyond a certain threshold, as the curves for length 40 and 60 are very similar. In this case, we see that the trajectory length does, indeed, punish the performance more than it does for the pointwise error, as the model tends to accumulate missclasified changepoints along the way."
  },
  {
    "objectID": "tutorials/analysis_bm.html#optional-load-the-data",
    "href": "tutorials/analysis_bm.html#optional-load-the-data",
    "title": "Benchmark: Brownian motion",
    "section": "(Optional) Load the data",
    "text": "(Optional) Load the data\nLoad the test set in case it is not in memory.\n\nds = load_dataset(n_change=\"1_to_4\", dim=dim, bm=True, name=\"test\")"
  },
  {
    "objectID": "tutorials/analysis_bm.html#get-the-predictions-3",
    "href": "tutorials/analysis_bm.html#get-the-predictions-3",
    "title": "Benchmark: Brownian motion",
    "section": "Get the predictions",
    "text": "Get the predictions\nLet’s get the predictions over the noisy trajectories. First of all, however, we will pre-compute the logarithm of our targets and rename some columns.\n\nds['y'] = ds['y_exp'].apply(torch.squeeze)\nds['y_log'] = ds['y'].apply(torch.log10)\n# ds['cp'] = ds['cp'].apply(lambda x: x.numpy())\nds = ds.drop(columns=['y_mod', 'y_exp', 'models', 'exps'])\n\nTo make the most out of our trajectories, we will add 128 random levels of noise to each of them. We sample \\(\\sigma_{\\text{noise}}\\in[10^{-6}, 10^0]\\) uniformly in log space.\n\nnoise_samples = 128\nnoise_max, noise_min = 0, -6\nnoise_range = noise_max - noise_min\nnoise_traj = torch.rand(ds.shape[0], noise_samples)*noise_range + noise_min\n\nJust like we have done at the beginning, we can compare the segment-wise prediction of STEP with the TA-MSD baseline.\n\nshape = (ds.shape[0], len(ds.x[0]), noise_traj.shape[1])\npred_noise = torch.zeros(shape)\npred_seg_noise = torch.zeros(shape) \npred_tamsd_noise = torch.zeros(shape)\n\nfor i, (x, cps) in tqdm(ds[['x','cp']].iterrows()):\n    noise = torch.randn(noise_samples, *x.T.shape)*10**noise_traj[i]\n    noisy_x = x.T.unsqueeze(0) + noise.unsqueeze(-1).unsqueeze(-1)\n    noisy_x -= noisy_x[:, 0].unsqueeze(1)\n    split_x = split_tensor(noisy_x.transpose(1, 0), cps)\n    \n    pred_noise[i] = predict(learn_diff.model, noisy_x).T\n    \n    pred_seg, pred_tamsd = [], []\n    for seg_x in split_x:\n        seg_x = (seg_x - seg_x[0]).transpose(1, 0)\n        ones = torch.ones(seg_x.shape[1])\n        pred = to_detach(learn_diff.model(seg_x.cuda()).squeeze())\n        pred_seg.append(pred)\n        pred_tamsd.append(torch.stack([ones*diffusion_coefficient_tamsd(s)\n                                       for s in seg_x]))\n        \n    pred_seg_noise[i] = torch.cat(pred_seg, axis=-1).T\n    pred_tamsd_noise[i] = torch.cat(pred_tamsd, axis=-1).T\n    \npredictions = dict(zip(['full', 'seg', 'tamsd'],\n                       [pred_noise, pred_seg_noise, pred_tamsd_noise]))\n\n\n\n\nWith the predictions, let’s compute the error performed at every point as a function of the noise to signal ratio \\(\\sigma_{\\text{noise}}/D\\).\nSince the diffusion coefficient changes along the trajectories, we need to compute \\(\\sigma_{\\text{noise}}/D\\) at every time step of all the trajectories.\n\ny = torch.stack([t for t in ds['y_log'].values])\nrel_noise = noise_traj.unsqueeze(1) - y.unsqueeze(-1)\n\nNow we can compute the relative errors performed by every method at each time step.\n\nerrors = {k: p - y.unsqueeze(-1) if k != 'tamsd'\n          else p/(10**y.unsqueeze(-1)) - 1 # Already get rel error for tamsd\n          for k, p in predictions.items()}\n\nSince we’re dealing with infinitely many combinations of \\(\\sigma_{\\text{noise}}\\) and \\(D\\), we compute the error as a function of small intervals of \\(\\sigma_{\\text{noise}}/D\\).\n\nbins = torch.linspace(rel_noise.min(), rel_noise.max(), 100)\nnoise_err, noise_err_std, x, counts = [], [], [], []\n\nfor low, high in tqdm(zip(bins[:-1], bins[1:])):\n    mask = (rel_noise &gt;= low) & (rel_noise &lt;= high)\n    x.append((low + high)/2)\n    counts.append(mask.float().sum())\n    rel_errors = [(10**err[mask] - 1).abs() if k != 'tamsd'\n                  else err[mask].abs() \n                  for k, err in errors.items()]\n    noise_err.append(tensor([rel_err.mean() for rel_err in rel_errors]))\n    noise_err_std.append(tensor([rel_err.std() for rel_err in rel_errors]))\n    \nnoise_err = torch.stack(noise_err)\nnoise_err_std = torch.stack(noise_err_std)\nx = torch.stack(x)\ncounts = torch.stack(counts)\n\n\n\n\nLet’s save these to process later.\n\nfig_name = \"noise_analysis\"\nplot_path = (FIG_PATH/fig_name).with_suffix(\".pkl\")\nplot_data = (noise_err, noise_err_std, x, counts)\nwith open(plot_path, 'wb') as f:\n    pickle.dump(plot_data, f, protocol=pickle.HIGHEST_PROTOCOL)\n\nAnd let’s see what we got!\n\n\nCode\nsem = noise_err_std/counts.sqrt().unsqueeze(-1)\n\nplt.figure(figsize=(1.5*fig_size, fig_size))\nfor k, (err, s) in enumerate(zip(noise_err.T, sem.T)):\n    plt.semilogx(10**x, err, '-', linewidth=2., c=colors[k], label=labels[k])\n    plt.fill_between(10**x, err - s, err + s, alpha=0.5, color = colors[k])\nplt.legend(fontsize=14)\nplt.grid(alpha = alpha_grid)\nplt.xlim([10**(-4.5), 30])\nplt.ylim([0.15, 1.])\nplt.tick_params(labelsize=14)\nplt.xlabel(r\"$\\sigma_{noise}/D$\", fontsize=16)\nplt.ylabel(\"Relative error\", fontsize=16)\nplt.tick_params(labelsize=14)\n\n\n\n\n\nSTEP is significantly more resilient to localization noise than the TA-MSD method. It only gets outperformed at noise levels that are greater than the actual signal, which are unrealistic experimental conditions."
  },
  {
    "objectID": "source/data.html",
    "href": "source/data.html",
    "title": "Data",
    "section": "",
    "text": "We provide a set of variables with default information about the nature of the data and the default path to save it.\n\nROOT = Path(os.path.dirname(os.path.abspath('../')))\nDATA_PATH = ROOT/\"data/\"\nDATA_PATH.mkdir(exist_ok=True, parents=True)\nFIG_PATH = DATA_PATH/\"figures\"\nFIG_PATH.mkdir(exist_ok=True, parents=True)\nMODEL_PATH = ROOT/\"models\"\nMODEL_PATH.mkdir(exist_ok=True, parents=True)\n\nMODEL_DATA = {\n    0: {'name': 'attm', 'exps': (0.05, 1.)},\n    1: {'name': 'ctrw', 'exps': (0.05, 1.)},\n    2: {'name': 'fbm',  'exps': (0.05, 1.95)},\n    3: {'name': 'lw',   'exps': (1.05, 2.)},\n    4: {'name': 'sbm',  'exps': (0.05, 2.)}\n    }\n              \nDEFAULT_TOKEN = -1\n\nBy default, we keep the root of the repository in ROOT, from which we define DATA_PATH=ROOT/'data' and MODEL_PATH=ROOT/'models', subsequently, we define FIG_PATH=DATA_PATH/'figures'. We use these as default paths to save and load the data, the trained models and the output figures.\nThen, MODEL_DATA is a dictionary containing the information about the different anomalous diffusion models that we consider. And DEFAULT_TOKEN=-1 is the default value for the beginning of sequence token."
  },
  {
    "objectID": "source/data.html#anomalous-diffusion-segmentation-dataset",
    "href": "source/data.html#anomalous-diffusion-segmentation-dataset",
    "title": "Data",
    "section": "Anomalous diffusion segmentation dataset",
    "text": "Anomalous diffusion segmentation dataset\nWe simulate anomalous diffusion trajectories following a similar recipe to the proposed in andi_datasets for the AnDi challenge.\nAs we specify in MODEL_DATA, there are five anomalous diffusion models that we consider, each with a different range of anomalous diffusion exponent \\(\\alpha\\):\n\nAnnealed transit time (ATTM) with \\(\\alpha\\in\\left[0.05, 1\\right]\\).\nContinuous time random walk (CTRW) with \\(\\alpha\\in\\left[0.05, 1\\right]\\).\nFractional Brownian motion (FBM) with \\(\\alpha\\in\\left[0.05, 1.95\\right]\\).\nLévy Walk (LW) with \\(\\alpha\\in\\left[1.05, 2\\right]\\).\nScaled Brownian motion (SBM) with \\(\\alpha\\in\\left[0.05, 2\\right]\\).\n\nWe take \\(\\alpha\\) values in intervals of 0.05 within the specified ranges.\nFurthermore, we add localization noise in the form of white noise \\(\\sim\\mathcal{N}(0, \\sigma_{\\text{noise}})\\). We also show how to build a data augmentation scheme with localization noise, for which having noiseless trajectories is useful. Simply, specify noise=[0] for that.\n\nsource\n\nadd_localization_noise\n\n add_localization_noise (trajs, noise_amplitude=[0.01, 0.5, 1])\n\nAdds white noise with standard deviation noise_amplitude.\n\nsource\n\n\ncreate_andi_trajectories\n\n create_andi_trajectories (n_traj, max_t, dim, exponents, models,\n                           noise=[0.1, 0.5, 1.0])\n\nCreates anomalous diffusion trajectories.\nFor instance, we can generate a bunch of 2D FBM and SBM trajectories of 20 time steps and two levels of noise \\(\\sigma_{\\text{noise}}=\\left\\{0.1, 0.5\\right\\}\\). Furthermore, we can specify the desired values for \\(\\alpha\\). Since both models can have a wide range of values, let’s make them purely super-diffusive \\(\\alpha&gt;1\\).\n\nn_traj = 60\nmax_t = 20\ndim = 2\nexponents = np.arange(1.2, 2., 0.05)\nmodels = [2, 4] # FBM and SBM\nnoise = [0.1, 0.5]\ntrajectories = create_andi_trajectories(n_traj, max_t, dim, exponents, models, noise=noise)\n\nThe function create_andi_trajectories tries to balance the classes for diffusion model and \\(\\alpha\\). Usually, this results into little deviations from the specified number of trajectories. Sorry for the inconvenience!\n\n\nCode\nprint(f\"We asked for {n_traj} trajectories and got {trajectories.shape[0]}\")\n\n\nWe asked for 60 trajectories and got 62\n\n\nAs this uses andi_datasets.datasets_theory to generate the trajectories, the result is an \\(N\\times(2+d*T)\\) matrix, where \\(N\\) is the number of trajectories, \\(d\\) is the dimension, and \\(T\\) is the trajectory length. The first two columns contain the trajectory information: model and \\(\\alpha\\).\n\ntrajectories.shape\n\n(62, 42)\n\n\n\ntrajectories[:6, :2]\n\narray([[2.  , 1.2 ],\n       [2.  , 1.2 ],\n       [2.  , 1.25],\n       [2.  , 1.25],\n       [2.  , 1.3 ],\n       [2.  , 1.3 ]])\n\n\nHowever, this method is limited to exclusively generate trajectories without changes along the way. As we mention above, we use it as a building block to generate our heterogeneous trajectories.\n\nsource\n\n\nget_andids_fname\n\n get_andids_fname (n_change_points, max_t, dim, name='')\n\nReturns standardized file name for segmentation dataset.\n\nsource\n\n\ncreate_andi_segmentation_dataset\n\n create_andi_segmentation_dataset (n_traj:int, max_t:int=200, dim:int=1,\n                                   n_change_points:int=1, models:list=[0,\n                                   1, 2, 3, 4],\n                                   exponents:numpy.ndarray|None=None,\n                                   noise:list=[0.1, 0.5, 1.0],\n                                   path:pathlib.Path|str|None=None,\n                                   save:bool=True, name:str='', margin=10,\n                                   random_lengths=False)\n\nCreates a dataset for trajectory segmentation of anomalous diffusion.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nn_traj\nint\n\nNumber of trajectories\n\n\nmax_t\nint\n200\nMaximum trajectory length\n\n\ndim\nint\n1\nTrajectory dimension\n\n\nn_change_points\nint\n1\nNumber of changepoints in the trajectories\n\n\nmodels\nlist\n[0, 1, 2, 3, 4]\nDiffusion models to consider\n\n\nexponents\nnumpy.ndarray | None\nNone\nAnomalous exponents to consider. Defaults to full range\n\n\nnoise\nlist\n[0.1, 0.5, 1.0]\nNoise standard deviation\n\n\npath\npathlib.Path | str | None\nNone\nPath to save the data\n\n\nsave\nbool\nTrue\nSave or not the data\n\n\nname\nstr\n\nOptional name for the data set\n\n\nmargin\nint\n10\n\n\n\nrandom_lengths\nbool\nFalse\n\n\n\nReturns\nDataFrame\n\n\n\n\n\nLet’s create a segmentation dataset of a few trajectories.\n\nn_traj = 100\ndf = create_andi_segmentation_dataset(n_traj, save=False)\n\nThe resulting DataFrame contains trajectories with one change point (by default), and combines all possible diffusion models and anomalous diffusion exponents.\n\ndf.columns\n\nIndex(['dim', 'len', 'n_cp', 'cp', 'models', 'exps', 'x', 'y', 'y_mod',\n       'y_exp', 'noise'],\n      dtype='object')\n\n\nLet’s look at an example.\n\nx0 = df.loc[0]\nx0.exps, x0.models, x0.cp\n\n(tensor([0.2500, 0.2500]), tensor([1, 2]), tensor([113]))\n\n\nThis trajectory changes from CTRW with \\(\\alpha=0.25\\) to FBM with \\(\\alpha=0.25\\) at frame 113.\n\n\nCode\nplt.figure(figsize=(7,4))\nplt.plot(x0.x[0])\nplt.vlines(x0.cp.item(), min(x0.x[0]), max(x0.x[0]), linestyles='dashed', colors='k')\nplt.grid()\nplt.title(\"Trajectory with one change point\")\nplt.xlabel(\"Time step\")\nplt.ylabel(\"Position\");"
  },
  {
    "objectID": "source/data.html#brownian-motion",
    "href": "source/data.html#brownian-motion",
    "title": "Data",
    "section": "Brownian motion",
    "text": "Brownian motion\nWe simulate Brownian motion taking the displacements as white noise with standard deviation \\(\\sqrt{2D\\delta t}\\), where \\(D\\) is the diffusion coefficient and \\(\\delta t\\) is the time-step duration (we generally take \\(\\delta t=1\\)).\n\nsource\n\nbrownian_motion\n\n brownian_motion (n_traj, max_t, D, dim=1, dt=1)\n\nSimulate Brownian motion trajectories.\n\nsource\n\n\ncreate_bm_trajectories\n\n create_bm_trajectories (n_traj, max_t, Ds=[1.0], shuffle=True, dim=1,\n                         dt=1)\n\nSimulate Brownian motion trajectories with various diffusion coefficients.\nSimilar to create_andi_trajectories, create_bm_trajectories evenly distributes the amount of trajectories for each diffusion coefficient we consider.\n\nn_traj = 9\nmax_t = 5\ntrajectories = create_bm_trajectories(n_traj, max_t, dim=1, Ds=[1., 2.], shuffle=False)\ntrajectories.shape\n\n(8, 7)\n\n\nDespite only having one parameter: the diffusion coefficient \\(D\\), we still find two additional terms in the trajectory length which are, simply, two copies of \\(D\\). This is to keep a consistent formatting with the anomalous diffusion trajectories that need to store the model and \\(\\alpha\\).\n\nsource\n\n\nget_bmds_fname\n\n get_bmds_fname (n_change_points, max_t, dim, name='')\n\nReturns consistent file name for segmentation dataset.\n\nsource\n\n\ncreate_bm_segmentation_dataset\n\n create_bm_segmentation_dataset (n_traj:int, max_t:int=200, dim:int=1,\n                                 n_change_points:int=1,\n                                 Ds:collections.abc.Iterable|None=None,\n                                 path:pathlib.Path|str|None=None,\n                                 save:bool=True, name:str='', margin=10,\n                                 random_lengths=False)\n\nCreates a segmentation dataset to tell between diffusion coefficients.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nn_traj\nint\n\nNumber of trajectories\n\n\nmax_t\nint\n200\nMaximum trajectory length\n\n\ndim\nint\n1\nTrajectory dimension\n\n\nn_change_points\nint\n1\nNumber of changepoints in the trajectories\n\n\nDs\ncollections.abc.Iterable | None\nNone\nDiffusion coefficients to consider defaults to logspace(-3, 3)\n\n\npath\npathlib.Path | str | None\nNone\nPath to save the data\n\n\nsave\nbool\nTrue\nSave or not the data\n\n\nname\nstr\n\nOptional name for the data set\n\n\nmargin\nint\n10\n\n\n\nrandom_lengths\nbool\nFalse\n\n\n\nReturns\nDataFrame\n\n\n\n\n\nThe behaviour is very similar to create_andi_segmentation_dataset. Let’s see an example.\n\nN = 100\ndf = create_bm_segmentation_dataset(N, Ds=[10, 50, 100], save=False)\n\n\nx0 = df.iloc[1]\nx0.exps, x0.cp\n\n(tensor([100.,  10.]), tensor([54]))\n\n\nThe trajectory changes from \\(D=100\\) to \\(D=10\\) at the 54th time-step.\n\n\nCode\nplt.figure(figsize=(7,4))\nplt.plot(x0.x[0])\nplt.vlines(x0.cp.item(), min(x0.x[0]), max(x0.x[0]), linestyles='dashed', colors='k')\nplt.grid()\nplt.title(\"Trajectory with one change point\")\nplt.xlabel(\"Time step\")\nplt.ylabel(\"Position\");\n\n\n\n\n\n\n\nATTM trajectories\nAnnealed transit time (ATTM) is an anomalous diffusion model consisting of piecewise normal diffusion. Every segment has a random diffusion coefficient \\(D\\) drawn with probability \\[P(D) = \\frac{D^{\\sigma - 1}\\exp(-D/b)}{b^\\sigma\\Gamma(\\sigma)}\\,,\\] with parameters \\(\\sigma\\) and \\(b\\). The residence time in each diffusive state, \\(\\tau\\), depends on the magnitude of the diffusion coefficient: \\[P_\\tau(\\tau|D)=\\frac{D^\\gamma}{k}\\exp(-\\tau D^\\gamma/k)\\,,\\] with parameters \\(\\gamma\\) and \\(k\\). The parameters \\(\\sigma\\) and \\(\\gamma\\) in these distributions determine the anomalous exponent \\(\\alpha=\\sigma/\\gamma\\), whenever \\(\\sigma&lt;\\gamma&lt;\\sigma+1\\). Thus, for every \\(\\alpha\\) there are infinitely many valid combinations of \\(\\sigma, \\,\\gamma\\).\nIn andi_datasets, these parameters are randomly sampled given a fixed \\(\\alpha\\). Here, we wish to extract \\(\\sigma\\) and \\(\\gamma\\) and, thus, we need a consistent way to simulate ATTM trajectories with those parameters fixed.\n\n\n\n\n\n\nNote\n\n\n\nIn our work, we use ATTM trajectories to show how to characterize anomalous diffusion directly from changes in normal diffusion.\n\n\n\nsource\n\n\ncreate_fixed_attm_trajs\n\n create_fixed_attm_trajs (n_traj, max_t, sigma, gamma)\n\nCreates 2-D ATTM trajectories with fixed sigma and gamma.\nLet’s generate some ATTM trajectories with fixed \\(\\sigma=0.3\\) and \\(\\gamma=0.4\\), meaning that \\(\\alpha=0.75\\).\n\nn_traj = 2\nmax_t = 15\nsigma, gamma = 0.3, 0.4\ntrajs, ds = create_fixed_attm_trajs(n_traj, max_t, sigma, gamma)\n\n\n\nCode\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(7, 3), constrained_layout=True)\naxes[0].plot(trajs[0].T)\naxes[0].set_xlabel(\"Time\", fontsize=16)\naxes[0].set_ylabel(\"Position\", fontsize=16)\naxes[0].tick_params(labelsize=14)\n\naxes[1].semilogy(ds[0])\naxes[1].set_xlabel(\"Time\", fontsize=16)\naxes[1].set_ylabel(\"D\", fontsize=16)\naxes[1].tick_params(labelsize=14)"
  },
  {
    "objectID": "source/data.html#datasets-with-variable-number-of-change-points",
    "href": "source/data.html#datasets-with-variable-number-of-change-points",
    "title": "Data",
    "section": "Datasets with variable number of change points",
    "text": "Datasets with variable number of change points\nSo far we have shown how to build data sets with a fixed number of changepoints. In order to make a dataset that contains a variable number of change points, we can simply combine several of those in a smart way.\nThis will make our models much more robust and allow us to generalize better to experimental data with an arbitrary number of changes along the trajectories.\n\nsource\n\ncombine_datasets\n\n combine_datasets (datasets, shuffle=True)\n\nCombines data sets together.\n\n\nExample: Brownian motion\nWith this code, we have generated the main test set of Brownian motion trajectories to validate our models.\n\nN_per_set = 12000\nmax_t = 200\ndim = 2\nDs = np.logspace(-3, 3, 1000) \ncps = [1, 2, 3, 4]\n# Choose a function to create datasets either brownian motion or anomalous diffusion\nds_fun = partial(create_bm_segmentation_dataset,\n                 max_t=max_t, dim=dim, Ds=Ds, save=False)\n\n\ndatasets = [ds_fun(N_per_set, n_change_points=n_cp) for n_cp in cps]\ndataset = combine_datasets(datasets)\n\nsave_path = DATA_PATH/get_bmds_fname(f'{min(cps)}_to_{max(cps)}', max_t, dim, 'test')\ndataset.to_pickle(save_path)\n\n\n\nExample: anomalous diffusion\nWith this code, we have generated the main test set of anomalous diffusion trajectories to validate our models.\n\nN_per_set = 12500\nmax_t = 200\ndim = 2 \ncps = [1, 2, 3, 4]\n# Choose a function to create datasets either brownian motion or anomalous diffusion\nds_fun = partial(create_andi_segmentation_dataset,\n                 models=models, max_t=max_t, dim=dim, noise=[0.], save=False)\n\n\ndatasets = [ds_fun(N_per_set, n_change_points=n_cp) for n_cp in cps]\ndataset = combine_datasets(datasets)\n\nsave_path = DATA_PATH/get_andids_fname(f'{min(cps)}_to_{max(cps)}', max_t, dim, 'test')\ndataset.to_pickle(save_path)"
  },
  {
    "objectID": "source/baselines.html",
    "href": "source/baselines.html",
    "title": "Baselines",
    "section": "",
    "text": "The diffusion properties of a particle are capture in its mean squared displacement (MSD) \\(\\langle x^2\\rangle = 2d Dt^\\alpha\\), where \\(d\\) is the dimension, \\(D\\) is the diffusion coefficient and \\(\\alpha\\) is the anomalous diffusion exponent. A common technique to study single-particle diffusion is to estimate the MSD with the time-averaged mean squared displacement (TA-MSD).\n\nsource\n\n\n\n tamsd (x:torch.Tensor, dt:int=1)\n\nTime-averaged mean squared displacement of a trajectory x in dt intervals.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx\nTensor\n\nInput trajectory of shape [length, dim]\n\n\ndt\nint\n1\nt-lag: time interval to compute displacements\n\n\nReturns\nfloat\n\n\n\n\n\nFrom the TA-MSD, we can compute both \\(D\\) and \\(\\alpha\\) looking at its scaling with \\(t\\). In Brownian motion, we can extract the diffusion coefficient through a linear fit of the TA-MSD \\(\\propto 2dDt\\) over time, as the slope is \\(2dD\\). In anomalous diffusion, we can perform a linear fit in logarithmic space, since it follows a power-law TA-MSD \\(\\propto t^\\alpha\\).\n\nsource\n\n\n\n\n anomalous_exponent_tamsd (x:torch.Tensor, t_lag:Iterable=[])\n\nEstimates the anomalous exponent fitting the tmsd in log-log scale for different t-lags.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx\nTensor\n\nInput trajectory of shape [length, dim]\n\n\nt_lag\nIterable\n[]\nt-lags to consider. Defautls to [2,…,max(5, 10% length)]\n\n\nReturns\nfloat\n\nAnomalous exponent\n\n\n\n\nsource\n\n\n\n\n diffusion_coefficient_tamsd (x:torch.Tensor, t_lag:Iterable=[1, 2])\n\nEstimates the diffusion coefficient fitting the tmsd for different dt.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx\nTensor\n\nInput trajectory of shape [length, dim]\n\n\nt_lag\nIterable\n[1, 2]\nt-lags to consider for the fit. [1, 2] is optimal for Brownian motion\n\n\nReturns\nfloat\n\nDiffusion coefficient\n\n\n\nLet’s see an example with Brownian motion. First, with our brownian_motion function, we can simulate a few trajectories with different diffusion coefficients.\n\nmax_t = 10000\nDs = np.array([0.5, 1., 5., 20])[:, None, None] # Extra dimensions to broadcast\ndim = 2\n\nnp.random.seed(7)\ntrajs = tensor(brownian_motion(len(Ds), max_t, Ds, dim=dim))\n\nLet’s compute the diffusion coefficients for the trajectories.\n\n[diffusion_coefficient_tamsd(traj.T) for traj in trajs]\n\n[0.5010303556919097, 0.9403451681137086, 4.982022762298584, 19.222974777221676]\n\n\nWe can do a similar analysis for anomalous diffusion. Let’s use the andi_datasets library to generate a few fractional brownian motion trajectories with different \\(\\alpha\\).\n\nad = datasets_theory()\nalphas = [0.1, 0.5, 1., 1.5]\nnp.random.seed(7)\ntrajs = ad.create_dataset(T=max_t, N_models=1, exponents=alphas,\n                          models=[2], dimension=dim)\ntrajs = tensor(trajs[:, 2:]).reshape(len(alphas), max_t, dim)\n\n\n[anomalous_exponent_tamsd(traj) for traj in trajs]\n\n[0.1301758215732175,\n 0.47395024375992173,\n 0.9880268080088149,\n 1.4136567214095137]"
  },
  {
    "objectID": "source/baselines.html#local-convex-hull-method",
    "href": "source/baselines.html#local-convex-hull-method",
    "title": "Baselines",
    "section": "Local convex hull method",
    "text": "Local convex hull method\nThe local convex hull method allows us to detect changepoints between two diffusive states in a trajectory. However, it does not provide any information about the properties of the segments.\n\nsource\n\nhull_diameter\n\n hull_diameter (hull)\n\nDiameter of the local convex hull.\n\nsource\n\n\nconvex_hull_cp\n\n convex_hull_cp (traj:numpy.ndarray, tau:int=10, method:str='volume')\n\nDetect the changepoints in traj with the local convex hull method.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntraj\nndarray\n\nTrajectory to study\n\n\ntau\nint\n10\nSize of the sliding window\n\n\nmethod\nstr\nvolume\nProperty of interest: “volume” or “diameter”\n\n\nReturns\nndarray\n\nChangepoints along the trajectory\n\n\n\nThis method relies on computing properties of the local convex hull conformed by a set of \\(\\tau\\) points along a trajectory. Whenever we encounter large changes in these properties, it signals a change in the diffusion mode. We typically consider the volume or the diameter of the hull.\nTo identify the changes, the method relies on a simple heuristic: we compute the mean of the property of interest along the trajectory and we mark a changepoint whenever we cross the mean value.\nLet’s see an example with a trajectory. We consider a 2D Brownian motion trajectory with two diffusive modes: a slow and a fast one. To simulate the fast one, we multiply the trajectory displacements by a factor \\(\\gt1\\), effectively increasing the diffusion coefficient by its square.\n\nT = 1000\ncps = np.array([400, 600])\n\nnp.random.seed(7)\ntraj = np.random.randn(T, 2)\ntraj[slice(*cps)] = 2.5*traj[slice(*cps)] # 2.5x factor displacements between cps\ntraj = traj.cumsum(0)\n\nThe resulting trajectory has two changepoints in which we switch from slow to fast and fast to slow, respectively.\nTo build some intuition about convex hulls, let’s look at the local convex hull of the first 10 points of the trajectory.\n\npoints = traj[:10]\nhull = ConvexHull(points)\n\n\n\nCode\nplt.plot(hull.points[:, 0], hull.points[:, 1], 'o-')\nfor simplex in hull.simplices:\n    plt.plot(hull.points[simplex, 0], hull.points[simplex, 1], 'k-')\n\n\n\n\n\nTo distinguish between both diffusive states, we compute the local convex hull properties (diameter and volume) over a sliding window of size \\(\\tau\\) along the trajectories.\n\ntau = 10\nmax_t = traj.shape[0] - 2*tau\nSd = np.zeros(max_t)\nSv = np.zeros(max_t)\n\nfor k in range(max_t):   \n    hull = ConvexHull(traj[k:(k+2*tau)])\n    Sd[k] = hull_diameter(hull)\n    Sv[k] = hull.volume\n\nThis allows us to extract the changepoints by looking at the points where the diameter or volume over time cross their mean value over time. This is what we do to find the changepoints in convex_hull_cp.\n\nchangepoints_vol = convex_hull_cp(traj, tau=tau, method=\"volume\")\nchangepoints_diam = convex_hull_cp(traj, tau=tau, method=\"diameter\")\n\nIn the figures below, we see all the information together. The changepoints (red dots) are always marked in the time-step prior to crossing the mean-value line.\n\n\nCode\nfig, axes = plt.subplots(1, 2, figsize=(9, 3.5), constrained_layout=True)\naxes[0].plot(Sd)\naxes[0].scatter(changepoints_diam, Sd[changepoints_diam], c='r', label=\"Changepoints\")\naxes[0].axhline(Sd.mean(), label='Mean', c='C1')\naxes[0].legend()\naxes[0].fill_betweenx(np.arange(Sd.max()), on, off, zorder=-1, alpha=0.1, color='k', lw=0)\naxes[0].set_xlabel('Time', fontsize=14); axes[0].set_ylabel(r'$S_d$', fontsize=14)\naxes[0].set_title(\"Local convex hull diameter\", fontsize=16)\n\naxes[1].plot(Sv)\naxes[1].scatter(changepoints_vol, Sv[changepoints_vol], c='r', label=\"Changepoints\")\naxes[1].axhline(Sv.mean(), label='Mean', c='C1')\naxes[1].legend()\naxes[1].fill_betweenx(np.arange(Sv.max()), on, off, zorder=-1, alpha=0.1, color='k', lw=0)\naxes[1].set_xlabel('Time', fontsize=14); axes[1].set_ylabel(r'$S_v$', fontsize=14)\naxes[1].set_title(\"Local convex hull volume\", fontsize=16);"
  },
  {
    "objectID": "source/baselines.html#ruptures",
    "href": "source/baselines.html#ruptures",
    "title": "Baselines",
    "section": "Ruptures",
    "text": "Ruptures\nThe ruptures library implements a kernel change point detection algorithm (see their review paper) performing a piecewise constant fit of the input signal.\nThe algorithm can either take a fixed number of changepoints to allocate, or infer the number by balancing the accuracy of the fit with a penalty for adding new changepoints. In most of our applications, we do not know the number of changepoints beforehand (which is the beauty of STEP!).\n\nsource\n\nruptures_cp\n\n ruptures_cp (x:numpy.ndarray, pen:float=1.0, kernel='linear', min_size=2,\n              jump=1, params=None)\n\nReturns the change points of signal x, excluding the initial and final times.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx\nndarray\n\nInput signal with shape [length, dim]\n\n\npen\nfloat\n1.0\nPenalty for the changepoint prediction\n\n\nkernel\nstr\nlinear\n\n\n\nmin_size\nint\n2\n\n\n\njump\nint\n1\n\n\n\nparams\nNoneType\nNone\n\n\n\nReturns\nndarray\n\nChangepoints along the trajectory\n\n\n\nThis algorithm is particularly well-suited to post-process our model predictions, which are (quasi) pointwise constant. Furthermore, unlike the local convex hull method, it is not limited to just two “states”.\nLet’s see an example of what could be a typical application of ruptures_cp. First, we will create a synthetic model prediction with some noise.\n\nmax_t = 250\ncps = [20, 70, 150]\nvalues = [-1., 3., 1., 2.]\n\nnp.random.seed(7)\npred = np.concatenate([[v]*(c1 - c0) for v, c0, c1 in zip(values, [0]+cps, cps+[max_t])])\npred += 0.5*np.random.randn(*pred.shape)\n\nNow let’s perform the changepoint detection over this noisy prediction considering different penalties.\n\npenalties = [1, 2, 5, 100]\ncps_pens = [ruptures_cp(pred, pen=pen) for pen in penalties]\n\n\n\nCode\nplt.figure(figsize=(6, 4))\nplt.plot(pred, label=\"Prediction\")\nfor pen, cp in zip(penalties, cps_pens):\n    segment_fit = [[pred[c0:c1].mean()]*(c1-c0) for c0, c1 in zip([0]+cp, cp+[max_t])]\n    plt.plot(np.concatenate(segment_fit), label=f\"Fit pen={pen}\")\nplt.legend()\nplt.xlabel(\"Time\", fontsize=14)\nplt.ylabel(\"Pred\", fontsize=14);\n\n\n\n\n\nFor this case, a penalty of \\(5\\) is just right to recover the ground truth value of our signal. However, if we didn’t know the ground truth beforehand, a penalty of \\(2\\) would also provide a reasonable result."
  }
]